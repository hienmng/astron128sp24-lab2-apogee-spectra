{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ddb65a",
   "metadata": {},
   "source": [
    "# Lab 2: Modeling Stellar Spectra\n",
    "\n",
    "Created: Tue Mar 5 1:11 PM, 2024\n",
    "<br>\n",
    "Updated: Fri Mar 29 7:00 PM, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b69bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import fitsio\n",
    "import io\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import scipy.stats\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import time as TIME\n",
    "\n",
    "from arviz import plot_trace as traceplot\n",
    "from astropy import units as units\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.timeseries import LombScargle\n",
    "from astroquery.gaia import Gaia\n",
    "from astroquery.utils.tap.core import TapPlus\n",
    "from fitsio import FITS, FITSHDR\n",
    "from matplotlib import gridspec\n",
    "from numpy.polynomial.chebyshev import chebfit, chebval\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from re import sub\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_context('notebook')\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 25\n",
    "plt.rcParams['axes.labelsize'] = 25\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "figures_dir = 'figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a5a6c",
   "metadata": {},
   "source": [
    "# 1. APOGEE Spectra\n",
    "\n",
    "*Download a subset of the APOGEE DR16 spectra in the form of $\\texttt{apStar}$ files. APOGEE spectra are sorted into different directories on the SDSS server based on their \"Field\", a few-digit string identifying their location in the sky. Download all the spectra with the following 4 randomly chosen fields: \"M15\", \"N6791\", \"K2_C4_168-21\", and \"060+00\". There should be 3036 spectra.*\n",
    "\n",
    "###### Notes\n",
    "The Two Micron All-Sky Survey (2MASS) was an astronomical survey of the sky conducted in the short-wavelength infrared at three frequency bands (J, H, and K) near 2 $\\mu$m.\n",
    "\n",
    "###### Bulk data download\n",
    "I followed the [bulk data download tutorial](https://live-sdss4org-dr16.pantheonsite.io/data_access/bulk/) and used APOGEE data release 16 [(dr16)](https://data.sdss.org/sas/dr16/apogee/spectro/redux/r12/stars/apo25m/). Note that $\\texttt{apo25m}$ are for stars observed at the Apache Point Observatory in the North, while $\\texttt{lco25m}$ contains stars observed at Las Campanas Observatory in the South. I searched with $\\texttt{CMD + F}$ for the 4 randomly chosen fields that are listed above, then used rsync to download the files. The rsync commands are:\n",
    "<br>\n",
    "\n",
    "$\\texttt{rsync -aLvz --include \"apStar-*.fits\"}$\n",
    "<br>\n",
    "$\\texttt{--exclude \"*\" --prune-empty-dirs --progress}$\n",
    "<br>\n",
    "$\\texttt{rsync://data.sdss.org/dr16/apogee/spectro/redux/r12/stars/apo25m/Field}$\n",
    "\n",
    "where 'Field' is replaced by the directory of the randomly chosen fields. In the cell below, I create a function to run the rsync in terminal as a subprocess through python. I also reference a 'http2rsync' function from the [bulk data download tutorial](https://live-sdss4org-dr16.pantheonsite.io/data_access/bulk/), which converts a 'http' URL into a rsync compatible URL. I downloaded more than 3036 spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsync_subprocess(file_name, file_dir, url):\n",
    "    \"\"\"\n",
    "    NOTE: This function is not working as expected,\n",
    "    it fetches all files in the URL and does not filter\n",
    "    for the input 'file_name'.\n",
    "    \n",
    "    Synchronize a specific file from a remote server to a local directory using rsync with subprocess.Popen.\n",
    "\n",
    "    Parameters:\n",
    "    - file_name (str): The name of the file to be synchronized.\n",
    "    - file_dir (str): The local directory where the file will be synchronized.\n",
    "    - url (str): The URL of the remote server where the file is located.\n",
    "\n",
    "    Returns:\n",
    "    - int: Return code of the rsync subprocess.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert the provided URL to an rsync-compatible URL\n",
    "        rsync_url = http2rsync(url)\n",
    "        \n",
    "        # Define the include pattern to only include the specified file\n",
    "        include_pattern = f'--include={file_name}'\n",
    "        \n",
    "        # Define the exclude pattern to exclude all files except the specified one\n",
    "        exclude_pattern = '--exclude=\"*\"'\n",
    "        \n",
    "        # Execute the rsync command using subprocess.Popen\n",
    "        process = subprocess.Popen([\n",
    "            'rsync',                    # Command to execute\n",
    "            '-aLvz',                    # Options: archive, verbose, compression, show progress\n",
    "            include_pattern,            # Include the specified file\n",
    "            exclude_pattern,            # Exclude all other files\n",
    "            '--prune-empty-dirs',       # Remove empty directories after synchronization\n",
    "            '--progress',               # Show progress during synchronization\n",
    "            rsync_url,                  # Source URL\n",
    "            file_dir                    # Destination directory\n",
    "        ])\n",
    "        return process.wait()  # Wait for process to finish and return the returncode\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 1  # Return a non-zero value to indicate failure\n",
    "\n",
    "def http2rsync(url):\n",
    "    \"\"\"\n",
    "    Convert a valid SDSS HTTP URL to the rsync equivalent.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The SDSS HTTP URL to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - str: The rsync equivalent URL.\n",
    "    \"\"\"\n",
    "    # Define the regular expression pattern with named groups\n",
    "    pattern = r'https?://(data|mirror)\\.sdss\\.org/sas/dr(?P<dr>[0-9]+)/(?P<rest>.*)$'\n",
    "    \n",
    "    # Replace the HTTP URL with the rsync equivalent using the named groups\n",
    "    rsync_url = sub(pattern, r'rsync://\\1.sdss.org/dr\\g<dr>/\\g<rest>', url)\n",
    "    \n",
    "    return rsync_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b2e1b",
   "metadata": {},
   "source": [
    "I have downloaded files for fields \"M15\", \"N6791\", and \"K2_C4_168-21\" via terminal command line. I tested the subprocess function for field \"060+00\". Note: the url labels the field as \"060%2B00\", which is incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe878de",
   "metadata": {},
   "source": [
    "*Each spectrum should be in its own $\\texttt{apStar}$ \".fits\" file, with a name like \"apStar-rYY-2MX+X.fits\". YY identifies the version of the reduction pipeline used to process the spectrum, and 2MX+X is the 2MASS ID of the target. Each $\\texttt{apStar}$ file contains individual visit and coadded multi-visit spectra for one star. The coadded spectra have already been Doppler shifted to the barycentric frame. *\n",
    "<br>\n",
    "\n",
    "***Explain what this means, and why the Doppler shift will be different for each visit.***\n",
    "<br>\n",
    "\n",
    "Multiple-visit spectra are the combined spectra of stars that were observed multiple times to increase the signal-to-noise (S/N) ratio of the data set. In this context, the barycentric frame is a frame of reference around the barycenter, or center-of-mass, of the solar system. Barycentric correction is the subtraction of the Earth's relative radial velocity from the a star's observed radial velocity. The Doppler shift correction is necessary because Earth's orbit around the Sun changes the observed radial velocity of the star. It is also a possibility that the star is in a dynamic system, such as a binary system, that complicates its observed radial velocity.\n",
    "<br>\n",
    "\n",
    "*The $\\texttt{apStar}$ file also contain the associated error arrays and a quality flag bitmask, plus some other information. The data model is described in detail on the SDSS website. Read in each spectrum and reconstruct the wavelength array.*\n",
    "\n",
    "###### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/apStar/M15/apStar-r12-2M21275176+1219275.fits'\n",
    "with fits.open(filename, memmap=True) as hdul:\n",
    "    hdul.info()\n",
    "    info = hdul[1].header\n",
    "    data = hdul[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c343073",
   "metadata": {},
   "source": [
    "Row no. 1 is flux data, no. 2 is uncertainty in flux data, and no. 3 are the bitmasks. **Find out what the other rows contain?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80910ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7aaf9",
   "metadata": {},
   "source": [
    "***What are the units of spectra? Explain what these units mean.***\n",
    "<br>\n",
    "\n",
    "Info of the flux header documents the units for flux in cgs-units. Flux is the amount of energy rate per area per wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89169892",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i, spectrum in enumerate(data):\n",
    "    plt.plot(\n",
    "        spectrum, \n",
    "        label=f'Spectrum {i + 1}',\n",
    "        zorder=len(data) - i\n",
    "    )\n",
    "\n",
    "plt.xlabel('Wavelength Bins')\n",
    "plt.ylabel(r'Flux $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$')\n",
    "plt.title('Spectra''\\n''M15/2M21275176+1219275')\n",
    "plt.legend(frameon=False, loc='lower left')\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'diagnostic_spectra_example.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f25a0",
   "metadata": {},
   "source": [
    "Some spectra has multiple spectrum because of repeated observations. I extract the first spectrum whenever this is the case, since the first spectrum is the combined spectra.\n",
    "<br>\n",
    "\n",
    "The wavelengths in the fits files are in log scale, so we need to convert it back to regular wavelengths. CRVAL1 is the center of a pixel and CRDELT1 are the step sizes. The wavelength is computed using\n",
    "<br>\n",
    "$$ \\lambda = 10^{\\rm \\, CRVAL1 \\, + \\, i \\, \\cdot \\, CRDELT1}$$\n",
    "<br>\n",
    "where $i$ is the index of a pixel in each spectrum. I referenced this [example](https://live-sdss4org-dr16.pantheonsite.io/irspec/catalogs/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334780d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_fit_file(file_path):\n",
    "    \"\"\"\n",
    "    Selects a random FITS file from the specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Directory of the FITS file\n",
    "    \n",
    "    Returns:\n",
    "    - random_file_path (str): Directory of the randomly chosen FITS file\n",
    "    - random_file_name (str): Name of the randomly chosen FITS file\n",
    "    \"\"\"\n",
    "    files = os.listdir(file_path)\n",
    "    files = [file for file in files if file.endswith('.fits')]\n",
    "    \n",
    "    random_file_name = random.choice(files)\n",
    "    random_file_path = os.path.join(file_path, random_file_name)\n",
    "    \n",
    "    return random_file_path, random_file_name\n",
    "\n",
    "def get_spectrum_data(file_path):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - file_path (str): The directory path where the FITS files are located.\n",
    "\n",
    "    Returns:\n",
    "    - wavelength (numpy.ndarray): Array of wavelengths corresponding to the spectrum.\n",
    "    - spectrum (numpy.ndarray): Array of flux values for the spectrum.\n",
    "    - error (numpy.ndarray): Array of error values for the spectrum.\n",
    "    - mask (numpy.ndarray): Array of mask values for the spectrum.\n",
    "    \"\"\"\n",
    "    f = fits.open(file_path)\n",
    "    spectra = f[1].data\n",
    "    \n",
    "    # picks out combined spectra\n",
    "    if len(np.shape(spectra)) > 1:\n",
    "        spectrum = f[1].data[0]\n",
    "        errors = f[2].data[0]\n",
    "        masks = f[3].data[0]\n",
    "    # or just the one spectra\n",
    "    else:\n",
    "        spectrum = f[1].data\n",
    "        errors = f[2].data\n",
    "        masks = f[3].data\n",
    "    \n",
    "    # reconstruct wavelengths\n",
    "    CRVAL1 = f[1].header['CRVAL1']    # pixel center\n",
    "    CRDELT1 = f[1].header['CDELT1']   # pixel step size\n",
    "    wavelengths = 10**np.arange(CRVAL1, CRVAL1 + len(spectrum)*CRDELT1, CRDELT1)\n",
    "\n",
    "    return wavelengths, spectrum, errors, masks\n",
    "\n",
    "def extract_star_field(file_path):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - file_path (str): The directory path of the FITS file.\n",
    "\n",
    "    Returns:\n",
    "    - star_name (str): The name of the star extracted from the file name.\n",
    "    - field_name_from_path (str): The name of the field extracted from the directory path.\n",
    "    \"\"\"\n",
    "    # extract file name without extension\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # extract star name\n",
    "    star_name = file_name.split('-')[2]\n",
    "    \n",
    "    # extract field name\n",
    "    field_name_from_path = os.path.basename(os.path.dirname(file_path))\n",
    "    \n",
    "    return star_name, field_name_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6fe80",
   "metadata": {},
   "source": [
    "*Plot an example spectrum (flux vs. wavelength).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths of chosen fields\n",
    "file_path_apStar = [\n",
    "    'data/apStar/M15/',\n",
    "    'data/apStar/N6791',\n",
    "    'data/apStar/K2_C4_168-21',\n",
    "    'data/apStar/060+00'\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(13,10), sharex=True)\n",
    "for i, file_path in enumerate(file_path_apStar):\n",
    "    # get random file from each field\n",
    "    random_file_path, random_file_name = get_random_fit_file(file_path)\n",
    "    \n",
    "    # get spectra data\n",
    "    wavelengths, spectrum, errors, masks = get_spectrum_data(random_file_path)\n",
    "    \n",
    "    # get star and field names for plotting\n",
    "    star_name, field_name = extract_star_field(random_file_path)\n",
    "    \n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    axs[row, col].plot(\n",
    "        wavelengths, \n",
    "        spectrum, \n",
    "        linewidth=1.5,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    axs[row, col].set_title(\n",
    "        f'{field_name}''\\n'f'{star_name}',\n",
    "        size=20\n",
    "    )\n",
    "    if row == 1:\n",
    "        axs[row, col].set_xlabel(\n",
    "            r'$\\lambda$ $\\left[\\AA\\right]$',\n",
    "            size=20\n",
    "        )\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\n",
    "            r'Flux $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$',\n",
    "            size=20\n",
    "        )\n",
    "    axs[row, col].ticklabel_format(\n",
    "        style='sci',\n",
    "        axis='both',\n",
    "        scilimits=(0,0),\n",
    "        useMathText=True\n",
    "    )\n",
    "    \n",
    "    axs[row, col].minorticks_on()\n",
    "    \n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'diagnostic_apStar_random_spectra.pdf',\n",
    "#     format='pdf',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40511eef",
   "metadata": {},
   "source": [
    "# 2. Stellar Properties of Red Giants\n",
    "\n",
    "*To build a training set, we also need to know the stellar properties (\"labels\") that have been derived for each spectrum by the ASPCAP pipeline [Garcia-Perez et al. 2015](https://ui.adsabs.harvard.edu/abs/2016AJ....151..144G/abstract). These can be found in the [\"allStar\" catalog](https://live-sdss4org-dr16.pantheonsite.io/irspec/spectro_data/), and the labels for each spectrum can be found [here](https://data.sdss.org/datamodel/files/APOGEE_ASPCAP/APRED_VERS/ASPCAP_VERS/allStar.html).*\n",
    "\n",
    "###### Downloading allStar catalog\n",
    "\n",
    "I downloaded the file $\\texttt{allStar-r12-l33.fits}$ directly from [here](https://live-sdss4org-dr16.pantheonsite.io/irspec/spectro_data/). I can also download using $\\texttt{rsync_subprocess}$, but that is unnecessary since there is only one file. I found the spectrum labels and their description [here](https://data.sdss.org/datamodel/files/APOGEE_ASPCAP/APRED_VERS/ASPCAP_VERS/allStar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46878f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "allStar_file_path = 'data/allStar/allStar-r12-l33.fits'\n",
    "\n",
    "# define columns to be read \n",
    "# from FITS file along with \n",
    "# their data types\n",
    "allStar_columns_and_types = {\n",
    "    'APOGEE_ID': (str,),\n",
    "    'FILE': (str,),\n",
    "    'FIELD': (str,),\n",
    "    'SNR': (np.float32,),\n",
    "    'TEFF': (np.float32,),\n",
    "    'TEFF_ERR': (np.float32,),\n",
    "    'LOGG': (np.float32,),\n",
    "    'LOGG_ERR': (np.float32,),\n",
    "    'FE_H': (np.float32,),\n",
    "    'FE_H_ERR': (np.float32,),\n",
    "    'MG_FE': (np.float32,),\n",
    "    'MG_FE_ERR': (np.float32,),\n",
    "    'SI_FE': (np.float32,),\n",
    "    'SI_FE_ERR': (np.float32,),\n",
    "    'ASPCAPFLAG': (np.int32,)\n",
    "}\n",
    "\n",
    "allStar_data = fitsio.read(\n",
    "    allStar_file_path, \n",
    "    columns = list(allStar_columns_and_types.keys())\n",
    ")\n",
    "\n",
    "allStar_df = pd.DataFrame(allStar_data)\n",
    "\n",
    "# convert data types of columns\n",
    "for column, data_type in allStar_columns_and_types.items():\n",
    "    allStar_df[column] = allStar_df[column].astype(*data_type)\n",
    "    \n",
    "print(f'Number of stars: {len(allStar_df)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31fd9",
   "metadata": {},
   "source": [
    "*Due to data quality issues, not all labels have been derived for all stars. Discard all spectra for which:*\n",
    "* *There are no labels for $T_{\\rm eff}$, $\\log g$, $\\rm [Fe/H]$, $\\rm [Mg/Fe]$, $\\rm [Si/Fe]$*\n",
    "* *Low SNR spectra; $\\rm SNR < 50$, as reported in the allStar catalog*\n",
    "* *Dwarf stars ($\\log g < 4$, or $T_{\\rm eff} < 5,700 K$); the focus of this lab is on giants.*\n",
    "* *Stars with low metallicity $\\rm [Fe/H] < -1$.*\n",
    "\n",
    "*There should be 1855 stars.*\n",
    "\n",
    "###### Filtering dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of chosen fields\n",
    "chosen_fields = ['M15', 'N6791', 'K2_C4_168-21', '060+00']\n",
    "\n",
    "# slice dataframe for chosen fields\n",
    "allStar_field_df = allStar_df[allStar_df['FIELD'].isin(chosen_fields)]\n",
    "\n",
    "# discard spectra without labels for \n",
    "# Teff, log g, [Fe/H], [Mg/Fe], [Si/Fe]\n",
    "labels_to_check = ['TEFF', 'LOGG', 'FE_H', 'MG_FE', 'SI_FE']\n",
    "for label in labels_to_check:\n",
    "    allStar_field_df = allStar_field_df[allStar_field_df[label] > -9999]\n",
    "\n",
    "# discard spectra with low signal-to-noise ratio\n",
    "allStar_field_df = allStar_field_df[allStar_field_df['SNR'] > 50]\n",
    "\n",
    "# discard dwarf stars spectra\n",
    "allStar_field_df = allStar_field_df[allStar_field_df['LOGG'] < 4]\n",
    "allStar_field_df = allStar_field_df[allStar_field_df['TEFF'] < 5700]\n",
    "\n",
    "# discard low metallicity spectra\n",
    "allStar_field_df = allStar_field_df[allStar_field_df['FE_H'] > -1]\n",
    "\n",
    "# reset the index after filtering\n",
    "allStar_field_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Number of stars that fit criteria: {len(allStar_field_df)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a65db4",
   "metadata": {},
   "source": [
    "*Visualize their distribution in label space using a corner plot.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deef0ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Teff = allStar_field_df['TEFF']\n",
    "logg = allStar_field_df['LOGG']\n",
    "FE_H = allStar_field_df['FE_H']\n",
    "MG_FE = allStar_field_df['MG_FE']\n",
    "SI_FE = allStar_field_df['SI_FE']\n",
    "\n",
    "allStar_array = np.vstack(np.transpose([Teff, logg, FE_H, MG_FE, SI_FE]))\n",
    "\n",
    "figure = corner.corner(\n",
    "    allStar_array,\n",
    "    labels = [r'$T_{\\rm eff}$', r'$\\log g$', '[Fe/H]', '[Mg/Fe]', '[Si/Fe]'],\n",
    "    show_titles = True\n",
    ")\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'result_allStar_labels_corner.pdf',\n",
    "#     format='pdf',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76d3ce",
   "metadata": {},
   "source": [
    "*Explain how the cut on $\\log g$ effectively distinguishes between dwarfs and giants. Consider a solar-mass star, calculate the expected value of $\\log g$ on the main sequence (when $R \\sim 1 R_{\\odot}$), just before the helium flash (when $R \\sim 100 R_{\\odot}$), and during the core helium burning (when $R \\sim 15 R_{\\odot}$).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e561b7f",
   "metadata": {},
   "source": [
    "# 3. Identifying Bad Pixels with apStar Bitmasks\n",
    "\n",
    "*Use the apStar bitmasks to identify bad pixels in each spectrum (i.e. pixels where sky subtraction failed, there was a cosmic ray strike, or something else bad happened). Set the uncertainty in these pixels to a large value, so that they will not contribute significantly to the likelihood function in later fitting. The bitmask are a bit unintuitive but are described on in APOGEE data model. To see what each bit means for APOGEE spectra, check the \"APOGEE_PIXMASK: APOGEE pixel level mask bits\" dropdown menu. Based on experience, bits $0-7$ and $12$ are the most important; the others can probably be ignored.*\n",
    "\n",
    "I'll do the next two problems for star 2M19395986+2341280, then generalize the code for random spectra later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 1 star\n",
    "cp1star_path = 'data/apStar/060+00/apStar-r12-2M19395986+2341280.fits'\n",
    "\n",
    "cp1_wvl, cp1_spc, cp1_err, cp1_msk = get_spectrum_data(cp1star_path)\n",
    "cp1_star_name, cp1_field_name = extract_star_field(cp1star_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5eb4b",
   "metadata": {},
   "source": [
    "###### Inspecting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(cp1star_path, memmap=True) as hdul:\n",
    "    info = hdul[1].header\n",
    "    spectra = hdul[1].data\n",
    "    errors = hdul[2].data\n",
    "    masks = hdul[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481596cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul[3].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cp1_err)\n",
    "plt.xlabel('Wavelength Bins')\n",
    "plt.ylabel(\n",
    "    r'Flux Error $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$'\n",
    ")\n",
    "plt.title('Spectra Errors''\\n'f'{cp1_field_name}/{cp1_star_name}')\n",
    "plt.ticklabel_format(\n",
    "    style='sci',\n",
    "    axis='y',\n",
    "    scilimits=(0,0),\n",
    "    useMathText=True\n",
    ")\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'diagnostic_cp1star_default_errors.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4953c",
   "metadata": {},
   "source": [
    "###### Inspecting masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45377b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cp1_msk)\n",
    "plt.xlabel('Wavelength Bins')\n",
    "plt.ylabel('Flag Mask [bitwise]')\n",
    "plt.title('Spectra Flag Masks''\\n'f'{cp1_field_name}/{cp1_star_name}')\n",
    "plt.ticklabel_format(\n",
    "        style='sci',\n",
    "        axis='y',\n",
    "        scilimits=(0,0),\n",
    "        useMathText=True\n",
    ")\n",
    "plt.minorticks_on()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'diagnostic_cp1star_flag_masks.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb276ec",
   "metadata": {},
   "source": [
    "###### Converting mask integers to binary representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1_unique_masks = np.unique(cp1_msk)\n",
    "print(cp1_unique_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b567bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert integer to binary string\n",
    "def integer_to_binary(integer):\n",
    "    binary = bin(integer)[2:]\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f91aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1_msk_bin = [integer_to_binary(value) for value in cp1_unique_masks]\n",
    "\n",
    "print('Flag masks for which bits 0-7, and/or 12, are set to true:')\n",
    "\n",
    "for index, integer in enumerate(cp1_unique_masks):\n",
    "    # reverse the binary string\n",
    "    # so index 0 is bit 0\n",
    "    cp1_msk_bin_rvrs = cp1_msk_bin[index][::-1]\n",
    "    # separate case for mask integer\n",
    "    # with bit string longer than 1\n",
    "    if len(cp1_msk_bin_rvrs)>1:\n",
    "        # filter for bits 0-7 and 12\n",
    "        cp1_bin_filtered = cp1_msk_bin_rvrs[0:8] + cp1_msk_bin_rvrs[12:13]\n",
    "        # check if a bit is set to TRUE\n",
    "        if '1' in cp1_bin_filtered:\n",
    "            print(f'{integer}: {cp1_bin_filtered}')\n",
    "    else:\n",
    "        # case of bit string length 1\n",
    "        if '1' in cp1_msk_bin_rvrs:\n",
    "            print(f'{integer}: {cp1_msk_bin_rvrs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db2607",
   "metadata": {},
   "source": [
    "If bitmasks for bits 0-7 and 12 are not zero, then define new errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_pixel_uncertainty_alternate(errors, masks):\n",
    "#     new_errors = errors.copy()\n",
    "    \n",
    "#     for i in range(len(masks)):\n",
    "#         if (masks[i] & 0b1000011111111) != 0:\n",
    "#             new_errors[i] = 1.0e10\n",
    "    \n",
    "#     return new_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc527091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inflate errors\n",
    "def set_pixel_uncertainty(errors, masks):\n",
    "    \"\"\"\n",
    "    Set pixel uncertainties to a large value for flagged pixels in the spectrum.\n",
    "\n",
    "    Parameters:\n",
    "    - errors (numpy.ndarray): Array of error values for each pixel in the spectrum.\n",
    "    - masks (numpy.ndarray): Array of mask values indicating flags for each pixel.\n",
    "\n",
    "    Returns:\n",
    "    - errors_inflated (numpy.ndarray): Array of error values with inflated uncertainties.\n",
    "    \"\"\"\n",
    "    # initialize new errors\n",
    "    inflated_errors = errors.copy()\n",
    "    \n",
    "    # convert mask integers to binary\n",
    "    masks_binary = [integer_to_binary(n) for n in masks]\n",
    "    \n",
    "    for index, mask in enumerate(masks_binary):\n",
    "        # reverse index to start with 2^0\n",
    "        mask_binary_reversed = masks_binary[index][::-1]\n",
    "        # bit string longer than 1 digit\n",
    "        if len(mask_binary_reversed) > 1:\n",
    "            # filter for bits 0-7, 12\n",
    "            mask_binary_filtered = mask_binary_reversed[0:8] + mask_binary_reversed[12:13]\n",
    "            # bit(s) set to true (bad)\n",
    "            if '1' in mask_binary_filtered:\n",
    "                inflated_errors[index] = 1e10    # inflate error\n",
    "        # bit string is 1 digit\n",
    "        else:\n",
    "            # bit set to true (bad)\n",
    "            if '1' in mask_binary_reversed:\n",
    "                inflated_errors[index] = 1e10    # inflate error\n",
    "    \n",
    "    return inflated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a43455",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(10,10), sharex=True)\n",
    "\n",
    "axs[0].plot(cp1_err, linewidth=1.5)\n",
    "axs[0].set_title(f'{cp1_field_name}/{cp1_star_name}''\\n''Spectrum Raw Errors')\n",
    "axs[0].set_ylabel(\n",
    "    r'Error $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$'\n",
    ")\n",
    "axs[0].minorticks_on()\n",
    "axs[0].ticklabel_format(\n",
    "    style='sci',\n",
    "    axis='y',\n",
    "    scilimits=(0,0),\n",
    "    useMathText=True\n",
    ")\n",
    "\n",
    "axs[1].plot(cp1_err_inflated, linewidth=1.5)\n",
    "axs[1].set_title('Inflated Errors')\n",
    "axs[1].set_xlabel('Wavelength Bins')\n",
    "axs[1].set_ylabel(\n",
    "    r'Error $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$'\n",
    ")\n",
    "axs[1].minorticks_on()\n",
    "axs[1].ticklabel_format(\n",
    "    style='sci',\n",
    "    axis='y',\n",
    "    scilimits=(0,0),\n",
    "    useMathText=True\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'methods_bad_pixel_errors.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e4cda",
   "metadata": {},
   "source": [
    "Count the number of bad pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize counters for bad pixels with large errors\n",
    "num_pixels_new_err = 0 # number of bad pixels with new errors\n",
    "num_pixels_old_err = 0 # number of bad pixels from old errors\n",
    "\n",
    "# count pixels with modified and original uncertainties\n",
    "for i in range(len(cp1_err)):\n",
    "    if cp1_err_inflated[i] == 1.0e10:\n",
    "        num_pixels_new_err += 1\n",
    "    if cp1_err[i] == 1.0e10:\n",
    "        num_pixels_old_err += 1\n",
    "\n",
    "print(f'Number of bad pixels with new errors: {num_pixels_new_err}.')\n",
    "print(f'Number of bad pixels from old errors: {num_pixels_old_err}.')\n",
    "print(f'Total number of pixels: {len(cp1_err)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c027b7",
   "metadata": {},
   "source": [
    "# 4.\n",
    "\n",
    "*Before we fit spectra, we need to \"pseudo-continuum normalize\" them, as described in [Ness et al. 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract).* ***Explain what this means and why it is useful. What is the difference between pseudo-continuum normalization and \"true\" continuum normalization?***\n",
    "<br>\n",
    "\n",
    "*Developing a continuum normalization procedure from scratch is challenging: an iterative method is required to determine which wavelengths are insensitive to label changes, and thus good for fitting continuum). To find out more about this, read sections 2.3 and 5.3 of [Ness et al. 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract).*\n",
    "<br>\n",
    "\n",
    "*In this lab, we are making the problem a bit easier by providing you with a list of wavelengths $\\texttt{continuum_pixels_apogee.npz}$ that do not contain any strong absorption lines. In other words, the flux value at these wavelengths should not depend much on the spectral labels of the star, but only on its absolute magnitude and distance. ***Write a function that uses the flux in these wavelength pixels to estimate the continuum over the full APOGEE wavelength range.*** Section 2.3 of [Ness et al. 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract) should be useful. Because the APOGEE spectra are split over three chips, with gaps between the chips, your continuum-determination procedure will probably work better if you handle the three chips individually.*\n",
    "<br>\n",
    "\n",
    "*Normalize all your spectra and error arrays.* ***Plot some example un-normalized spectrum, the derived pseudo-continuum, and the normalized spectrum.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acc0c8",
   "metadata": {},
   "source": [
    "###### Defining wavelength ranges (chips) and trusted indices\n",
    "\n",
    "I use the wavelengths from the provided $\\texttt{continuum_pixels_apogee.npz}$ file to clean the spectra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb082a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine apogee wavelength grid\n",
    "apogee_grid = np.load('data/apogee_wavelength.npz')\n",
    "apogee_wvl = apogee_grid['wavelength']\n",
    "\n",
    "# use provided cannon wavelengths as trusted values\n",
    "cannon_data = np.load('data/cannon_continuum_apogee.npz')\n",
    "cannon_wavelengths = cannon_data['wavelengths']\n",
    "cannon_indices = cannon_data['trusted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce3667",
   "metadata": {},
   "source": [
    "Remove bad pixels using method from problem 3, using trusted wavelengths given by Cannon-derived continuum (section 5.3 of Ness et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_spectrum(file_path):\n",
    "    \"\"\"\n",
    "    Interpolate spectrum data onto provided fine wavelength grid\n",
    "    \"\"\"\n",
    "    wavelengths, spectrum, errors, masks = get_spectrum_data(file_path)\n",
    "    inflated_errors = set_pixel_uncertainty(errors, masks)\n",
    "    \n",
    "    # interpolate onto finer grid\n",
    "    fine_spectrum = np.interp(\n",
    "        apogee_wvl,\n",
    "        wavelengths,\n",
    "        spectrum\n",
    "    )\n",
    "    fine_errors = np.interp(\n",
    "        apogee_wvl,\n",
    "        wavelengths,\n",
    "        inflated_errors\n",
    "    )\n",
    "    \n",
    "    return fine_spectrum, fine_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trusted_spectrum(file_path):\n",
    "    fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "    \n",
    "    trusted_spectrum = fine_spectrum[cannon_indices]\n",
    "    trusted_errors = fine_errors[cannon_indices]\n",
    "    \n",
    "    return trusted_spectrum, trusted_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9cf67",
   "metadata": {},
   "source": [
    "Split the data into three separate wavelength chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfd3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define apogee wavelength chips\n",
    "apogee_chips = [\n",
    "    (15150, 15800),\n",
    "    (15890, 16430),\n",
    "    (16490, 16950)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f88b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chips(wavelengths, spectrum, errors, chip_ranges):\n",
    "\n",
    "    chip_wavelengths_list = []\n",
    "    chip_spectrum_list = []\n",
    "    chip_errors_list = []\n",
    "    \n",
    "    for chip_index, (start, end) in enumerate(chip_ranges):\n",
    "        start_index = np.searchsorted(wavelengths, start)\n",
    "#         print(f'Start wavelength and index for chip {chip_index + 1}: {start} at {start_index}.')\n",
    "        end_index = np.searchsorted(wavelengths, end)\n",
    "#         print(f'End wavelength and index for chip {chip_index + 1}: {end} at {end_index}.')\n",
    "        \n",
    "        wvl_chip = wavelengths[start_index:end_index]\n",
    "        spc_chip = spectrum[start_index:end_index]\n",
    "        err_chip = errors[start_index:end_index]\n",
    "        \n",
    "        chip_wavelengths_list.append(wvl_chip)\n",
    "        chip_spectrum_list.append(spc_chip)\n",
    "        chip_errors_list.append(err_chip)\n",
    "\n",
    "    chip_wavelengths = np.concatenate(chip_wavelengths_list)\n",
    "    chip_spectrum = np.concatenate(chip_spectrum_list)\n",
    "    chip_errors = np.concatenate(chip_errors_list)\n",
    "    \n",
    "    return chip_wavelengths, chip_spectrum, chip_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae481427",
   "metadata": {},
   "source": [
    "###### Plotting unnormalized spectrum of star 2M19395986+2341280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clean_unnormalized_spectrum(file_path, chip_ranges):    \n",
    "    fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "    \n",
    "    chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "        apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "    )\n",
    "    \n",
    "    star_name, field_name = extract_star_field(file_path)\n",
    "    \n",
    "    for chip_index, (start, end) in enumerate(chip_ranges):\n",
    "        start_index = np.searchsorted(chip_wavelengths, start)\n",
    "        end_index = np.searchsorted(chip_wavelengths, end)\n",
    "        \n",
    "        plt.plot(\n",
    "            chip_wavelengths[start_index:end_index],\n",
    "            chip_spectrum[start_index:end_index],\n",
    "            linewidth=1.5,\n",
    "            alpha=0.5,\n",
    "            label=f'chip {chip_index + 1}',\n",
    "            zorder=1\n",
    "        )\n",
    "    \n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel(r'Flux $\\left[10^{-17} \\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$')\n",
    "    plt.title('Clean Unnormalized Spectrum''\\n'f'{field_name}/{star_name}')\n",
    "    plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0), useMathText=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp1_spc_trusted, cp1_err_trusted = get_trusted_spectrum(cp1star_path)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plot_clean_unnormalized_spectrum(cp1star_path, apogee_chips)\n",
    "\n",
    "plt.plot(\n",
    "    cp1_wvl,\n",
    "    cp1_spc,\n",
    "    alpha=0.5,\n",
    "    label='raw',\n",
    "    zorder=0\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    cannon_wavelengths[cannon_indices],\n",
    "    cp1_spc_trusted,\n",
    "    marker='.',\n",
    "    s=10,\n",
    "    c='black',\n",
    "    label='cannon',\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.ylim(125, 425)\n",
    "plt.legend(frameon=True, ncol=2)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'result_cp1star_unnorm_spec.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c60a7",
   "metadata": {},
   "source": [
    "###### Constructing pseudo-continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b90fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pseudo_continuum_test0(file_path, chip_ranges, poly_order):\n",
    "    \n",
    "#     fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "\n",
    "#     trusted_spectrum, trusted_errors = get_trusted_spectrum(file_path)\n",
    "    \n",
    "#     chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "#         apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "#     )\n",
    "\n",
    "#     coefficients_list = []\n",
    "#     continuum_wvl_list = []\n",
    "#     pseudo_continuum_list = []\n",
    "    \n",
    "#     for i, (start, end) in enumerate(chip_ranges):\n",
    "#         start_idx = np.searchsorted(chip_wavelengths, start)\n",
    "#         end_idx = np.searchsorted(chip_wavelengths, end)\n",
    "\n",
    "#         # compute the running quantile (e.g., upper 90th quantile)\n",
    "#         # across a 50 angstrom window\n",
    "#         kernel_size = 50\n",
    "#         if kernel_size % 2 == 0:\n",
    "#             kernel_size += 1  # make sure kernel_size is odd\n",
    "\n",
    "#         running_quantile = []\n",
    "#         for i in range(start_idx, end_idx):\n",
    "#             window = chip_spectrum[max(0, i - kernel_size // 2): min(i + kernel_size // 2 + 1, len(chip_spectrum))]\n",
    "#             window_sorted = np.sort(window)\n",
    "#             quantile_index = int(len(window_sorted) * 0.1)  # 10% from the top (upper 90th quantile)\n",
    "#             running_quantile.append(window_sorted[-quantile_index])\n",
    "\n",
    "#         running_quantile = np.array(running_quantile)\n",
    "\n",
    "#         if np.shape(chip_wavelengths[start_idx:end_idx])[0] != 0:\n",
    "#             # Chebyshev fitting to the running quantile\n",
    "#             coeffs = chebfit(\n",
    "#                 chip_wavelengths[start_idx:end_idx],\n",
    "#                 running_quantile,\n",
    "#                 deg=poly_order,\n",
    "#                 w=1/chip_errors[start_idx:end_idx]\n",
    "#             )\n",
    "\n",
    "#             x_values = np.linspace(\n",
    "#                 chip_wavelengths[start_idx],\n",
    "#                 chip_wavelengths[end_idx-1],\n",
    "#                 num=end_idx - start_idx\n",
    "#             )\n",
    "\n",
    "#             # compute pseudo-continuum\n",
    "#             y_values = chebval(x_values, coeffs)\n",
    "\n",
    "#             coefficients_list.append(coeffs)\n",
    "#             continuum_wvl_list.extend(x_values)\n",
    "#             pseudo_continuum_list.extend(y_values)\n",
    "    \n",
    "#     coefficients = np.array(coefficients_list)\n",
    "#     continuum_wavelengths = np.array(continuum_wvl_list)\n",
    "#     pseudo_continuum = np.array(pseudo_continuum_list)\n",
    "\n",
    "#     return continuum_wavelengths, pseudo_continuum, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pseudo_continuum_test1(file_path, chip_ranges, poly_order):\n",
    "    \n",
    "#     fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "\n",
    "#     trusted_spectrum, trusted_errors = get_trusted_spectrum(file_path)\n",
    "    \n",
    "#     chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "#         apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "#     )\n",
    "    \n",
    "#     coeffs = chebfit(\n",
    "#         cannon_wavelengths[cannon_indices],\n",
    "#         trusted_spectrum,\n",
    "#         deg=poly_order,\n",
    "#         w=1/trusted_errors\n",
    "#     )\n",
    "    \n",
    "#     pseudo_continuum = chebval(chip_wavelengths, coeffs)\n",
    "    \n",
    "#     return chip_wavelengths, pseudo_continuum, coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_continuum(file_path, chip_ranges, poly_order):\n",
    "    \n",
    "    fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "\n",
    "    trusted_spectrum, trusted_errors = get_trusted_spectrum(file_path)\n",
    "    \n",
    "    chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "        apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "    )\n",
    "\n",
    "    coefficients_list = []\n",
    "    continuum_wvl_list = []\n",
    "    pseudo_continuum_list = []\n",
    "    \n",
    "    for i, (start, end) in enumerate(chip_ranges):\n",
    "        # divide cannon continuum into chips\n",
    "        cannon_start_idx = np.searchsorted(cannon_wavelengths[cannon_indices], start)\n",
    "        cannon_end_idx = np.searchsorted(cannon_wavelengths[cannon_indices], end)\n",
    "        \n",
    "        # divide spectrum into chips\n",
    "        start_idx = np.searchsorted(chip_wavelengths, start)\n",
    "        end_idx = np.searchsorted(chip_wavelengths, end)\n",
    "        \n",
    "        # get pseudo-continuum coefficients\n",
    "        # from provided cannon continuum\n",
    "        coeffs = chebfit(\n",
    "            cannon_wavelengths[cannon_indices][cannon_start_idx:cannon_end_idx],\n",
    "            trusted_spectrum[cannon_start_idx:cannon_end_idx],\n",
    "            deg=poly_order,\n",
    "            w=1/trusted_errors[cannon_start_idx:cannon_end_idx]\n",
    "        )\n",
    "        \n",
    "        x_values = np.linspace(\n",
    "            chip_wavelengths[start_idx],\n",
    "            chip_wavelengths[end_idx-1],\n",
    "            num=end_idx - start_idx\n",
    "        )\n",
    "\n",
    "        # compute pseudo-continuum\n",
    "        y_values = chebval(x_values, coeffs)\n",
    "        \n",
    "        coefficients_list.append(coeffs)\n",
    "        continuum_wvl_list.extend(x_values)\n",
    "        pseudo_continuum_list.extend(y_values)\n",
    "    \n",
    "    coefficients = np.array(coefficients_list)\n",
    "    continuum_wavelengths = np.array(continuum_wvl_list)\n",
    "    pseudo_continuum = np.array(pseudo_continuum_list)\n",
    "\n",
    "    return continuum_wavelengths, pseudo_continuum, coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d4b92",
   "metadata": {},
   "source": [
    "###### Plot pseudo-continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239523ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pseudo_continuum(file_path, chip_ranges, poly_order):\n",
    "    star_name, field_name = extract_star_field(file_path)\n",
    "    \n",
    "    fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "    \n",
    "    chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "        apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "    )\n",
    "    \n",
    "    continuum_wavelengths, pseudo_continuum, coefficients = get_pseudo_continuum(\n",
    "        file_path, chip_ranges, poly_order\n",
    "    )\n",
    "    \n",
    "    for i, (start, end) in enumerate(chip_ranges):\n",
    "        start_idx = np.searchsorted(chip_wavelengths, start)\n",
    "        end_idx = np.searchsorted(chip_wavelengths, end)\n",
    "\n",
    "        plt.plot(\n",
    "            continuum_wavelengths[start_idx:end_idx],\n",
    "            pseudo_continuum[start_idx:end_idx],\n",
    "            linewidth=1.5,\n",
    "            label = f\"continuum {i+1}:\"\"\\n\"f\"{', '.join('{:.2e}'.format(coeff) for coeff in coefficients[i])}\"\n",
    "        )\n",
    "    \n",
    "    plt.title('Pseudo-Continuum Fit''\\n'f'{field_name}/{star_name}')\n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel(r'Flux ($10^{-17}$) $\\left[\\frac{\\rm erg}{{\\rm s \\, cm^2} \\, \\AA}\\right]$')\n",
    "    plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0), useMathText=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcb520",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "plot_clean_unnormalized_spectrum(cp1star_path, apogee_chips)\n",
    "plt.scatter(\n",
    "    cannon_wavelengths[cannon_indices],\n",
    "    cp1_spc_trusted,\n",
    "    marker='.',\n",
    "    s=10,\n",
    "    c='black',\n",
    "    label='cannon'\n",
    ")\n",
    "plot_pseudo_continuum(cp1star_path, apogee_chips, poly_order=2)\n",
    "plt.minorticks_on()\n",
    "plt.ylim(125, 425)\n",
    "plt.legend(frameon=False, bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'result_cp1star_pseudo_continuum.pdf',\n",
    "#     format='pdf',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfae23a",
   "metadata": {},
   "source": [
    "###### Pseudo-continuum normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_continuum_normalize(file_path, chip_ranges, poly_order):\n",
    "    fine_spectrum, fine_errors = interpolate_spectrum(file_path)\n",
    "    \n",
    "    chip_wavelengths, chip_spectrum, chip_errors = split_chips(\n",
    "        apogee_wvl, fine_spectrum, fine_errors, apogee_chips\n",
    "    )\n",
    "    \n",
    "    continuum_wavelengths, pseudo_continuum, coefficients = get_pseudo_continuum(\n",
    "        file_path, chip_ranges, poly_order\n",
    "    )\n",
    "    \n",
    "    pseudo_norm_spectra_list = []\n",
    "    pseudo_norm_errors_list = []\n",
    "    \n",
    "    for i, (start, end) in enumerate(chip_ranges):\n",
    "        start_index = np.searchsorted(chip_wavelengths, start)\n",
    "        end_index = np.searchsorted(chip_wavelengths, end)\n",
    "        \n",
    "        # normalize with derived pseudo-continuum\n",
    "        pseudo_norm_spectra = chip_spectrum[start_index:end_index]/pseudo_continuum[start_index:end_index]\n",
    "        pseudo_norm_errors = chip_errors[start_index:end_index]/pseudo_continuum[start_index:end_index]\n",
    "        \n",
    "        pseudo_norm_spectra_list.extend(pseudo_norm_spectra.tolist())\n",
    "        pseudo_norm_errors_list.extend(pseudo_norm_errors.tolist())\n",
    "    \n",
    "    pseudo_norm_spectra = np.array(pseudo_norm_spectra_list)\n",
    "    pseudo_norm_errors = np.array(pseudo_norm_errors_list)\n",
    "    \n",
    "    return continuum_wavelengths, pseudo_norm_spectra, pseudo_norm_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ffb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pseudo_norm_spectrum(file_path, chip_ranges, poly_order):\n",
    "    star_name, field_name = extract_star_field(file_path)\n",
    "    \n",
    "    continuum_wavelengths, pseudo_norm_spectra, pseudo_norm_errors = pseudo_continuum_normalize(\n",
    "        file_path, chip_ranges, poly_order\n",
    "    )\n",
    "\n",
    "    plt.axhline(1, linestyle='--', c='black')\n",
    "    \n",
    "    for i, (start, end) in enumerate(chip_ranges):\n",
    "        start_index = np.searchsorted(continuum_wavelengths, start)\n",
    "        end_index = np.searchsorted(continuum_wavelengths, end)\n",
    "        \n",
    "        plt.plot(\n",
    "            continuum_wavelengths[start_index:end_index],\n",
    "            pseudo_norm_spectra[start_index:end_index],\n",
    "            alpha=0.5,\n",
    "            label=f'chip {i + 1}'\n",
    "        )\n",
    "        \n",
    "#     plt.plot(\n",
    "#         continuum_wavelengths,\n",
    "#         pseudo_norm_spectra,\n",
    "#         alpha=0.5,\n",
    "#         label=f'pseudo-normalized'\n",
    "#     )\n",
    "    \n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0), useMathText=True)\n",
    "    plt.title('Pseudo-continuum Normalized Spectrum''\\n'f'{field_name}/{star_name}')\n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel('Normalized Flux')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad10ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plot_pseudo_norm_spectrum(cp1star_path, apogee_chips, poly_order=2)\n",
    "plt.minorticks_on()\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'result_cp1star_pseudo_norm_spectrum.pdf',\n",
    "#     format='pdf',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a0b6b",
   "metadata": {},
   "source": [
    "# 5. Training and cross-validation sets\n",
    "\n",
    "*Divide the cleaned spectra into randomly selected groups of roughly equal size. Designate one group the training set and the other the cross-validation set.*\n",
    "\n",
    "First, I extract $\\texttt{apStar}$ file names and field names from the $\\texttt{allStar}$ catalog. These stars have known stellar properties, or labels, derived from the $\\texttt{APOGEE/ASPCAP}$ pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "allStar_file_names_list = []\n",
    "\n",
    "allStar_file_names = np.array(allStar_field_df['FILE'])\n",
    "allStar_field_names = np.array(allStar_field_df['FIELD'])\n",
    "\n",
    "for i in range(len(allStar_file_names)):\n",
    "    allStar_file_name = allStar_field_names[i] + '/' + allStar_file_names[i]\n",
    "    allStar_file_names_list.append(allStar_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450fe3b",
   "metadata": {},
   "source": [
    "I use file name list from the $\\texttt{allStar}$ catalog to normalize all cross-matched spectrum from the $\\texttt{apStar}$ files downloaded in problem 1, using the functions developed in problems 3 and 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92521b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into equal size training and testing data sets\n",
    "file_list_train, file_list_test, label_list_train, label_list_test = train_test_split(\n",
    "    allStar_file_names_list, allStar_field_df, train_size = 0.5, random_state = 42\n",
    ")\n",
    "\n",
    "# normalize training and testing data sets\n",
    "wavelengths_list_train = []\n",
    "spectra_list_train = []\n",
    "errors_list_train = []\n",
    "\n",
    "wavelengths_list_test = []\n",
    "spectra_list_test = []\n",
    "errors_list_test = []\n",
    "\n",
    "for i_idx, file_name in enumerate(file_list_train):\n",
    "#     print(f'Training set {i_idx + 1}')\n",
    "    \n",
    "    # normalize training set\n",
    "    wvl_train, spc_train, err_train = pseudo_continuum_normalize(\n",
    "        'data/apStar/' + file_name,\n",
    "        apogee_chips,\n",
    "        poly_order=2\n",
    "    )\n",
    "    \n",
    "    wavelengths_list_train.append(wvl_train)\n",
    "    spectra_list_train.append(spc_train)\n",
    "    errors_list_train.append(err_train)\n",
    "\n",
    "for j_idx, file_name in enumerate(file_list_test):\n",
    "#     print(f'Testing set {j_idx + 1}')\n",
    "    \n",
    "    # normalize testing set\n",
    "    wvl_test, spc_test, err_test = pseudo_continuum_normalize(\n",
    "        'data/apStar/' + file_name,\n",
    "        apogee_chips,\n",
    "        poly_order=2\n",
    "    )\n",
    "    \n",
    "    wavelengths_list_test.append(wvl_test)\n",
    "    spectra_list_test.append(spc_test)\n",
    "    errors_list_test.append(err_test)\n",
    "\n",
    "wavelengths_train = np.array(wavelengths_list_train)\n",
    "spectra_train = np.array(spectra_list_train)\n",
    "errors_train = np.array(errors_list_train)\n",
    "\n",
    "wavelengths_test = np.array(wavelengths_list_test)\n",
    "spectra_test = np.array(spectra_list_test)\n",
    "errors_test = np.array(errors_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(wavelengths_train))\n",
    "print()\n",
    "print(np.shape(spectra_train))\n",
    "print()\n",
    "print(np.shape(errors_train))\n",
    "print()\n",
    "\n",
    "print(np.shape(wavelengths_test))\n",
    "print()\n",
    "print(np.shape(spectra_test))\n",
    "print()\n",
    "print(np.shape(errors_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mass_pseudo_normalize(file_name_list, chip_ranges, poly_order):\n",
    "#     # initialize empty lists to store data\n",
    "#     wavelengths_list = []\n",
    "#     spectra_list = []\n",
    "#     errors_list = []\n",
    "    \n",
    "#     # define directory for apStar files\n",
    "#     apStar_files_dir = 'data/apStar/'\n",
    "    \n",
    "#     # normalize apStar from directory\n",
    "#     # that are also listed in allStar\n",
    "#     for file_name in file_name_list:\n",
    "#         wvl, spc, err = pseudo_continuum_normalize(\n",
    "#             apStar_files_dir + file_name,\n",
    "#             chip_ranges,\n",
    "#             poly_order\n",
    "#         )\n",
    "#         wavelengths_list.append(wvl)\n",
    "#         spectra_list.append(spc)\n",
    "#         errors_list.append(err)\n",
    "        \n",
    "# #     wavelengths = np.array(wavelengths_list)\n",
    "# #     spectra = np.array(spectra_list)\n",
    "# #     errors = np.array(errors_list)\n",
    "    \n",
    "#     return wavelengths_list, spectra_list, errors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019beec",
   "metadata": {},
   "source": [
    "# 6. Spectral Model\n",
    "\n",
    "*Use the training set to build a spectral model that predicts the spextrum at ***at each wavelength pixel*** as a function of the 5 labels: $T_{\\rm eff}$, $\\log g$, $\\left[\\rm Fe/H \\right]$, $\\left[\\rm Mg/Fe \\right]$, $\\left[\\rm Si/Fe \\right]$. Following [Ness et al.](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract), make the spectral model a 2nd-order polynomial in labels. The final spectral model will consist of thousands of individual models - one for each wavelength pixel - stitched together. In addition to the model free parameters, fit an intrinsic scatter term, $s_{\\lambda}^2$, at each wavelength. The intrinsic scatter is defined such that the variance in the observed normalized flux values at wavelength $\\lambda$ is given by $s_{\\lambda}^2 + \\sigma_{\\lambda}^2$, where $\\sigma_{\\lambda}$ is the uncertainty in the normalized flux.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6858c",
   "metadata": {},
   "source": [
    "### 6. a) Linear equation\n",
    "\n",
    "*Consider a single pixel of wavelength $\\lambda$. Let $\\mathbf{f}_{\\lambda}$ be an array containing the normalized flux in that pixel for all stars in the training set. Show that ***at a fixed value*** of $s_{\\lambda}^2$, the spectral model for the pixel can be described by a linear equation $\\mathbf{X}\\theta_{\\lambda} = \\mathbf{f}_{\\lambda}$, where $\\theta_{\\lambda}$ is an array of model parameters for that pixel and $\\mathbf{X}$ is a matrix that is the same for all pixels. ***What is $\\mathbf{X}$? For a spectral model that is a 2nd order polynomial in labels, how many free parameters are in $\\theta_{\\lambda}$ (here there are 5 labels)?*** Equation 8 of [Ness et al.](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract) should provide useful context.*\n",
    "\n",
    "A linear model relating the pseudo-normalized flux to stellar labels can be written as\n",
    "\n",
    "$$ f_{n\\lambda} = \\theta_{\\lambda}^T \\cdot \\ell_n + \\rm noise $$\n",
    "\n",
    "where for a single pixel/wavelength $\\lambda$ and a star $n$: $f_{n\\lambda}$ is the pseudo-normalized flux, $\\theta_{\\lambda}$ is the coefficient vector, and $\\ell_{n}$ is the label vector. Assume the noise is defined as\n",
    "\n",
    "$$ {\\rm noise} \\equiv \\left(s_{\\lambda}^2 + \\sigma_{n\\lambda}^2\\right)\\xi_{n\\lambda} $$\n",
    "\n",
    "where $\\xi_{n\\lambda}$ is a Gaussian random number with zero mean and unit variance.\n",
    "\n",
    "To make the model a second-order polynomial in labels, the label vector $\\ell_n$ is defined to be quadratic in the labels $\\ell_{nk}$\n",
    "\n",
    "$$\\ell_n \\equiv \\left[1,\\, \\ell_{n1} - \\overline{\\ell}_{n1},\\, \\cdots,\\, \\ell_{nK} - \\overline{\\ell}_{nK},\\, \\\\ \\left(\\ell_{n1} - \\overline{\\ell}_{n1}\\right)^2,\\, \\left(\\ell_{n1} - \\overline{\\ell}_{n1}\\right)\\left(\\ell_{n2} - \\overline{\\ell}_{n2}\\right),\\, \\cdots, \\\\\\left(\\ell_{nK} - \\overline{\\ell}_{nK}\\right)^2\\right]$$\n",
    "\n",
    "where $\\overline{\\ell}_{nk}$ are offsets (e.g. the means of the training data) and the element \"1\" allows for a linear offset in the fitting. The quadratic terms contain all possible products exactly once. Including the 1 element, the label vector $\\ell_n$ and coefficent vector $\\theta_{\\lambda}$ are both column vectors with dimension\n",
    "\n",
    "$$\\frac{1}{2}\\left(k + 1\\right)\\left(\\left(k+1\\right) + 1\\right) \\times 1 = \\frac{1}{2}\\left(k + 1\\right)\\left(k + 2\\right) \\times 1 $$\n",
    "\n",
    "That means there are 21 free parameters in $\\theta_{\\lambda}$ for 5 unique labels in $\\ell_n$. \n",
    "\n",
    "For $N_{\\rm ref}$ objects $n$ with known scatter $s_{\\lambda}^2$ (so that the noise term is a constant), the model can be written as\n",
    "\n",
    "$$ \\mathbf{f}_{\\lambda} = \\mathbf{X}\\theta_{\\lambda} $$\n",
    "\n",
    "where $\\mathbf{f}_{\\lambda}$ is now a $N_{\\rm ref} \\times 1$ pseudo-normalized flux vector and $\\theta_{\\lambda}$ is still the $\\frac{1}{2}\\left(k + 1\\right)\\left(k + 2\\right) \\times 1$ coefficient vector. Here $\\mathbf{X}$ is a $N_{\\rm ref} \\times \\frac{1}{2}\\left(k + 1\\right)\\left(k + 2\\right)$ matrix of labels \n",
    "\n",
    "$$ \\mathbf{X} \\equiv \\begin{pmatrix}\n",
    "        \\ell_1^T \\\\\n",
    "        \\vdots \\\\\n",
    "        \\ell_{N_{\\rm ref}}^T \\\\\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99541219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct X matrix\n",
    "label_names = ['TEFF', 'LOGG', 'FE_H', 'MG_FE', 'SI_FE']\n",
    "\n",
    "X_list = []\n",
    "\n",
    "# rescale each label with means of training data\n",
    "\n",
    "Teff_mean = np.mean(label_list_train.iloc[:]['TEFF'])\n",
    "logg_mean = np.mean(label_list_train.iloc[:]['LOGG'])\n",
    "FeH_mean = np.mean(label_list_train.iloc[:]['FE_H'])\n",
    "MgFe_mean = np.mean(label_list_train.iloc[:]['MG_FE'])\n",
    "SiFe_mean = np.mean(label_list_train.iloc[:]['SI_FE'])\n",
    "\n",
    "for i in range(len(label_list_train)):\n",
    "    Teff = label_list_train.iloc[i]['TEFF'] - Teff_mean\n",
    "    logg = label_list_train.iloc[i]['LOGG'] - logg_mean\n",
    "    FeH = label_list_train.iloc[i]['FE_H'] - FeH_mean\n",
    "    MgFe = label_list_train.iloc[i]['MG_FE'] - MgFe_mean\n",
    "    SiFe = label_list_train.iloc[i]['SI_FE'] - SiFe_mean\n",
    "    \n",
    "    row = [\n",
    "        1, Teff, logg, FeH, MgFe, SiFe,\n",
    "        Teff**2, Teff*logg, Teff*FeH, Teff*MgFe, Teff*SiFe,\n",
    "        logg**2, logg*FeH, logg*MgFe, logg*SiFe,\n",
    "        FeH**2, FeH*MgFe, FeH*SiFe,\n",
    "        MgFe**2, MgFe*SiFe, \n",
    "        SiFe**2\n",
    "    ]\n",
    "    \n",
    "    X_list.append(row)\n",
    "\n",
    "X = np.array(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35955688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(wavelengths_train))\n",
    "print(np.shape(spectra_train))\n",
    "print(np.shape(errors_train))\n",
    "print(f'Matrix X dimensions: {np.shape(X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct X matrix\n",
    "# label_names = ['TEFF', 'LOGG', 'FE_H', 'MG_FE', 'SI_FE']\n",
    "\n",
    "# X_list = []\n",
    "\n",
    "# # Rescale labels to order unity\n",
    "# label_means = {\n",
    "#     'TEFF': np.mean(label_list_train['TEFF']),\n",
    "#     'LOGG': np.mean(label_list_train['LOGG']),\n",
    "#     'FE_H': np.mean(label_list_train['FE_H']),\n",
    "#     'MG_FE': np.mean(label_list_train['MG_FE']),\n",
    "#     'SI_FE': np.mean(label_list_train['SI_FE'])\n",
    "# }\n",
    "\n",
    "# for i in range(len(label_list_train)):\n",
    "#     row = [1]\n",
    "#     for label in label_names:\n",
    "#         label_norm = label_list_train.iloc[i][label] - label_means[label]\n",
    "#         row.append(label_norm)\n",
    "    \n",
    "#     for j in range(len(label_names)):\n",
    "#         for k in range(j, len(label_names)):\n",
    "#             row.append(row[j + 1] * row[k + 1])\n",
    "    \n",
    "#     X_list.append(row)\n",
    "\n",
    "# spectra_train = np.array(spectra_list_train)\n",
    "# errors_train = np.array(errors_list_train)\n",
    "# X = np.array(X_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07946ab5",
   "metadata": {},
   "source": [
    "### 6. b) & c) $s_{\\lambda}^2$ & $\\theta_{\\lambda}$ for all pixels\n",
    "\n",
    "Single-pixel log-likelihood function, equation 4 from [Ness et al. 2015](https://ui.adsabs.harvard.edu/abs/2015ApJ...808...16N/abstract)\n",
    "\n",
    "$$ \\ln p \\left(f_{n\\lambda}\\,|\\,\\theta_{\\lambda}^{T},\\,l_n,\\,s_{\\lambda}^2\\right) = -\\frac{1}{2} \\frac{\\left(f_{n\\lambda} - \\theta_{\\lambda}^{T} \\cdot l_n\\right)^2}{s_{\\lambda}^2 + \\sigma_{n\\lambda}^2} - \\frac{1}{2} \\ln \\left(s_{\\lambda}^2 + \\sigma_{n\\lambda}^2\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(X, y):\n",
    "    return np.linalg.lstsq(X, y, rcond=-1)\n",
    "\n",
    "def get_coeff(wavelength_bin, sigma_scatter):\n",
    "#     flux_list = []\n",
    "#     sigma_total_list = []\n",
    "    \n",
    "#     # iterate through each star\n",
    "#     for i in range(np.shape(spectra_train)[0]):\n",
    "#         flux = spectra_train[i][wavelength_bin]\n",
    "# #         print(f'flux: {flux}') # single flux value check\n",
    "#         flux_list.append(flux)\n",
    "#     for j in range(np.shape(errors_train)[0]):\n",
    "#         sigma_total = np.sqrt(\n",
    "#             errors_train[j][wavelength_bin]**2 + sigma_scatter**2\n",
    "#         )\n",
    "# #         print(f'sigma total: {sigma_total}') # single sigma value check\n",
    "#         sigma_total_list.append(sigma_total)\n",
    "\n",
    "    flux_list = spectra_train[:, wavelength_bin]\n",
    "    sigma_total_list = np.sqrt(errors_train[:, wavelength_bin]**2 + sigma_scatter**2)\n",
    "\n",
    "#     print(f'flux vector dimension: {np.shape(flux_list)}') # flux vector dim check\n",
    "#     print(f'sigma total vector dimension: {np.shape(sigma_total_list)}') # sigma vector dim check\n",
    "    \n",
    "    \n",
    "#     sigma_total_array = np.array(sigma_total_list)\n",
    "#     Weights_array = np.sqrt(1/sigma_total_array)\n",
    "#     Weights = Weights_array.tolist()\n",
    "    Weights = np.sqrt(np.diag(1/sigma_total_list**2))\n",
    "    \n",
    "#     print(f'weights: {Weights}')\n",
    "#     print(f'weights shape: {np.shape(Weights)}')\n",
    "    \n",
    "    X_weighted = np.dot(Weights, X)\n",
    "#     print(f'weighted X dim: {np.shape(X_weighted)}')\n",
    "    flux_weighted = np.dot(flux_list, Weights)\n",
    "#     print(f'weighted flux vector dim: {np.shape(flux_weighted)}')\n",
    "    \n",
    "    thetas = least_squares(X_weighted, flux_weighted)[0]\n",
    "#     thetas = least_squares(X_weighted, flux_weighted)\n",
    "#     print(f'thetas vector dim: {np.shape(thetas)}')\n",
    "    \n",
    "    return thetas\n",
    "\n",
    "def log_likelihood(flux_data, flux_model, sigma_data, sigma_scatter):\n",
    "    \n",
    "    L = 0\n",
    "    \n",
    "    for i in range(len(flux_data)):\n",
    "#         print(flux_data[i])\n",
    "#         print(sigma_data[i])\n",
    "        exponential_term = -0.5 * (flux_data[i] - flux_model[i])**2/(sigma_data[i]**2 + sigma_scatter**2)\n",
    "        log_term = -0.5 * np.log(sigma_data[i]**2 + sigma_scatter**2)\n",
    "        # sum single pixel log likelihood function\n",
    "        L += exponential_term + log_term\n",
    "        \n",
    "    return L\n",
    "\n",
    "def get_intrinsic_scatter(wavelength_bin):\n",
    "    \n",
    "    scatter_grid = 10**np.linspace(-5,0,15)\n",
    "    \n",
    "#     flux_data_list = []\n",
    "#     sigma_data_list = []\n",
    "    \n",
    "    # iterate through each star\n",
    "#     for i in range(np.shape(spectra_train)[0]):\n",
    "#         flux_data = spectra_train[i][wavelength_bin]\n",
    "# #         print(f'flux: {flux_data}') # single flux value check\n",
    "#         flux_data_list.append(flux_data)\n",
    "#     for j in range(np.shape(errors_train)[0]):\n",
    "#         sigma_data = errors_train[j][wavelength_bin]\n",
    "# #         print(f'sigma total: {sigma_data}') # single sigma value check\n",
    "#         sigma_data_list.append(sigma_data)\n",
    "\n",
    "    flux_data_list = spectra_train[:, wavelength_bin]\n",
    "    sigma_data_list = errors_train[:, wavelength_bin]\n",
    "    \n",
    "#     print(f'flux data dim: {np.shape(flux_data_list)}')\n",
    "#     print(f'sigma data dim: {np.shape(sigma_data_list)}')\n",
    "    \n",
    "    L_list = []\n",
    "    thetas_list = []\n",
    "    \n",
    "    for scatter in scatter_grid:\n",
    "        thetas = get_coeff(wavelength_bin, scatter)\n",
    "        thetas_list.append(thetas)\n",
    "        \n",
    "        flux_model_list = np.matmul(X, thetas)\n",
    "#         print(f'flux model list: {flux_model_list}')\n",
    "#         print(f'flux model list dim: {np.shape(flux_model_list)}')\n",
    "        \n",
    "        L = log_likelihood(flux_data_list, flux_model_list, sigma_data_list, scatter)\n",
    "        L_list.append(L)\n",
    "    \n",
    "    # index for scatter and theta that maximizes likelihood\n",
    "    max_index = np.argmax(L_list)\n",
    "    \n",
    "#     print(f'extrema scatter: {scatter_grid[max_index]}')    # check single value\n",
    "#     print(f'extrema theta: {thetas_list[max_index]}')    # check single value\n",
    "    \n",
    "    return scatter_grid[max_index], thetas_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a0803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intrinsic_scatter_list = []\n",
    "# thetas for each pixel\n",
    "thetas_matrix = []\n",
    "\n",
    "# iterate through wavelength bin\n",
    "for wavelength_bin in range(np.shape(wavelengths_list_train)[1]):\n",
    "    scatter, thetas = get_intrinsic_scatter(wavelength_bin)\n",
    "    \n",
    "    intrinsic_scatter_list.append(scatter)\n",
    "    thetas_matrix.append(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a84d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(intrinsic_scatter_list))\n",
    "print(np.shape(thetas_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3351fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store values to txt to save time\n",
    "# np.savetxt('intrinsic_scatter_list.txt', intrinsic_scatter_list)\n",
    "# np.savetxt('thetas_matrix.txt', thetas_matrix)\n",
    "\n",
    "intrinsic_scatter_list = np.loadtxt('intrinsic_scatter_list.txt')\n",
    "thetas_matrix = np.loadtxt('thetas_matrix.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38a9aa",
   "metadata": {},
   "source": [
    "### 6. d) \n",
    "\n",
    "*With the trained spectral model consisting of parameters $\\left\\{\\theta_{\\lambda}\\right\\}$, write a function that takes a label vector for an arbitrary star and uses the model to predict the normalized spectrum.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_spectrum(file_name):\n",
    "    file_index = allStar_file_names_list.index(file_name)\n",
    "    \n",
    "    # rescale labels with means of training data\n",
    "    Teff = allStar_field_df.iloc[file_index]['TEFF'] - Teff_mean\n",
    "    logg = allStar_field_df.iloc[file_index]['LOGG'] - logg_mean\n",
    "    FeH = allStar_field_df.iloc[file_index]['FE_H'] - FeH_mean\n",
    "    MgFe = allStar_field_df.iloc[file_index]['MG_FE'] - MgFe_mean\n",
    "    SiFe = allStar_field_df.iloc[file_index]['SI_FE'] - SiFe_mean\n",
    "    \n",
    "    # label vector\n",
    "    row = [\n",
    "        1, Teff, logg, FeH, MgFe, SiFe,\n",
    "        Teff**2, Teff*logg, Teff*FeH, Teff*MgFe, Teff*SiFe,\n",
    "        logg**2, logg*FeH, logg*MgFe, logg*SiFe,\n",
    "        FeH**2, FeH*MgFe, FeH*SiFe,\n",
    "        MgFe**2, MgFe*SiFe, \n",
    "        SiFe**2\n",
    "    ]\n",
    "    \n",
    "    spectrum_model_list = []\n",
    "\n",
    "    for wavelength_bin in range(len(thetas_matrix)):\n",
    "        flux_model_value = np.matmul(row, thetas_matrix[wavelength_bin])\n",
    "        spectrum_model_list.append(flux_model_value)\n",
    "    \n",
    "    spectrum_model = np.array(spectrum_model_list)\n",
    "    \n",
    "    return spectrum_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992369dd",
   "metadata": {},
   "source": [
    "# 7.\n",
    "\n",
    "*To ensure that the model is working properly, use it to predict the spextrum of some of the objects in the training set from its labels. **Specifically, overplot the normalized spextrum of the star 2M03533659+2512012 and the model spextrum predicted for its labels. Show the wavelength range from 16000 to 161000 Angstroms.** The data and model spextra should look almost identical. Go over step 6 if that is not the case.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pseudo_norm_spectrum(file_path, chip_ranges, poly_order):\n",
    "    star_name, field_name = extract_star_field(file_path)\n",
    "    \n",
    "    continuum_wavelengths, pseudo_norm_spectra, pseudo_norm_errors = pseudo_continuum_normalize(\n",
    "        file_path, chip_ranges, poly_order\n",
    "    )\n",
    "\n",
    "    plt.axhline(1, linestyle='--', c='black')\n",
    "    \n",
    "#     for i, (start, end) in enumerate(chip_ranges):\n",
    "#         start_index = np.searchsorted(continuum_wavelengths, start)\n",
    "#         end_index = np.searchsorted(continuum_wavelengths, end)\n",
    "        \n",
    "#         plt.plot(\n",
    "#             continuum_wavelengths[start_index:end_index],\n",
    "#             pseudo_norm_spectra[start_index:end_index],\n",
    "#             alpha=0.5,\n",
    "#             label=f'chip {i + 1}'\n",
    "#         )\n",
    "        \n",
    "    plt.plot(\n",
    "        continuum_wavelengths,\n",
    "        pseudo_norm_spectra,\n",
    "        alpha=0.5,\n",
    "        label=f'pseudo-normalized'\n",
    "    )\n",
    "    \n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0), useMathText=True)\n",
    "    plt.title('Pseudo-continuum Normalized Spectrum''\\n'f'{field_name}/{star_name}')\n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel('Normalized Flux')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "star7_name_field = 'K2_C4_168-21/apStar-r12-2M03533659+2512012.fits'\n",
    "star7_path = 'data/apStar/K2_C4_168-21/apStar-r12-2M03533659+2512012.fits'\n",
    "\n",
    "star7_spc_model = model_spectrum(star7_name_field)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plot_pseudo_norm_spectrum(star7_path, apogee_chips, poly_order=2)\n",
    "\n",
    "plt.plot(wavelengths_list_train[0], star7_spc_model, linewidth=1.5, label='model')\n",
    "\n",
    "plt.xlim(15995, 16105)\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.minorticks_on()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'results_star7_spec_pseudo_vs_model.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50b6d1",
   "metadata": {},
   "source": [
    "# 8.\n",
    "\n",
    "***For each of the five labels $\\ell_i$, plot the gradient spectrum ${\\rm d}f_{\\lambda}/{\\rm d}\\ell_i$. This allows the identification of wavelengths that are most sensitive to a particular label. For the gradient spectra of $\\rm Si$ and $\\rm Mg$, mark the locations of strong known $\\rm Si$ and $\\rm Mg$ lines.***\n",
    "\n",
    "*Some well-known lines at $\\texttt{APOGEE}$ wavelengths can be found [here](https://github.com/jobovy/apogee/blob/main/apogee/spec/plot.py).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62501650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(file_name, label_index, e):\n",
    "    \n",
    "    spectrum_model = model_spectrum(file_name)\n",
    "    \n",
    "    file_index = allStar_file_names_list.index(file_name)\n",
    "    \n",
    "    # rescale labels with means of training data\n",
    "    labels = [\n",
    "        allStar_field_df.iloc[file_index]['TEFF'] - Teff_mean,\n",
    "        allStar_field_df.iloc[file_index]['LOGG'] - logg_mean,\n",
    "        allStar_field_df.iloc[file_index]['FE_H'] - FeH_mean,\n",
    "        allStar_field_df.iloc[file_index]['MG_FE'] - MgFe_mean,\n",
    "        allStar_field_df.iloc[file_index]['SI_FE'] - SiFe_mean\n",
    "    ]\n",
    "    \n",
    "    # add the displacement to the chosen label\n",
    "    labels[label_index] += e\n",
    "    \n",
    "    # construct label vector\n",
    "    row = [1] + labels\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(i, len(labels)):\n",
    "            row.append(labels[i] * labels[j])\n",
    "    \n",
    "    spectrum_model_list_e = []\n",
    "\n",
    "    for wavelength_bin in range(len(thetas_matrix)):\n",
    "        flux_model_value = np.matmul(row, thetas_matrix[wavelength_bin])\n",
    "        spectrum_model_list_e.append(flux_model_value)\n",
    "    \n",
    "    spectrum_model_e = np.array(spectrum_model_list_e)\n",
    "    \n",
    "    # compute gradient\n",
    "    gradient = (spectrum_model_e - spectrum_model) / e\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "def get_gradient_Teff(file_name):\n",
    "    return get_gradient(file_name, 0, 1e-2)\n",
    "\n",
    "def get_gradient_logg(file_name):\n",
    "    return get_gradient(file_name, 1, 1e-3)\n",
    "\n",
    "def get_gradient_FeH(file_name):\n",
    "    return get_gradient(file_name, 2, 1e-4)\n",
    "\n",
    "def get_gradient_MgFe(file_name):\n",
    "    return get_gradient(file_name, 3, 1e-4)\n",
    "\n",
    "def get_gradient_SiFe(file_name):\n",
    "    return get_gradient(file_name, 4, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradient(file_name, label_name, gradient, absorption_lines=None):\n",
    "    \n",
    "    star_field = file_name.split('/')\n",
    "    star_name = star_field[-1].split('-')[2].split('.')[0]\n",
    "    field_name = star_field[0]\n",
    "    \n",
    "    plt.plot(wavelengths_list_train[0], gradient, linewidth=1.5)\n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel(f'd f / d {label_name}')\n",
    "    plt.title(f'Gradient {label_name}\\n{field_name}/{star_name}')\n",
    "    \n",
    "    if absorption_lines:\n",
    "        for line in absorption_lines:\n",
    "            plt.axvline(x=line, color='r', linestyle='--')\n",
    "    \n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0), useMathText=True)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "def plot_gradient_Teff(file_name):\n",
    "    gradient_Teff = get_gradient_Teff(file_name)\n",
    "    \n",
    "    plot_gradient(file_name, r'$\\rm T_{eff}$', gradient_Teff)\n",
    "\n",
    "def plot_gradient_logg(file_name):\n",
    "    gradient_logg = get_gradient_logg(file_name)\n",
    "    \n",
    "    plot_gradient(file_name, r'$\\log \\rm g$', gradient_logg)\n",
    "\n",
    "def plot_gradient_FeH(file_name):\n",
    "    gradient_FeH = get_gradient_FeH(file_name)\n",
    "    \n",
    "    FeH_absorption_lines = [\n",
    "        15194.492, 15207.526, 15395.718, 15490.339,\n",
    "        15648.510, 15964.867, 16040.657, 16153.247,\n",
    "        16165.032\n",
    "    ]\n",
    "    \n",
    "    plot_gradient(\n",
    "        file_name,\n",
    "        r'$\\left[\\rm Fe/H\\right]$',\n",
    "        gradient_FeH,\n",
    "        absorption_lines=FeH_absorption_lines\n",
    "    )\n",
    "\n",
    "def plot_gradient_MgFe(file_name):\n",
    "    gradient_MgFe = get_gradient_MgFe(file_name)\n",
    "\n",
    "    MgFe_absorption_lines = [\n",
    "        15740.716, 15748.9, 15765.8,\n",
    "        15879.5, 15886.2, 15954.477\n",
    "    ]\n",
    "    \n",
    "    plot_gradient(\n",
    "        file_name,\n",
    "        r'$\\left[\\rm Mg/Fe\\right]$',\n",
    "        gradient_MgFe,\n",
    "        absorption_lines=MgFe_absorption_lines\n",
    "    )\n",
    "\n",
    "def plot_gradient_SiFe(file_name):\n",
    "    gradient_SiFe = get_gradient_SiFe(file_name)\n",
    "    \n",
    "    SiFe_absorption_lines = [\n",
    "        15361.161, 15376.831, 15833.602, 15960.063,\n",
    "        16060.009, 16094.787, 16215.670, 16680.770,\n",
    "        16828.159\n",
    "    ]\n",
    "    \n",
    "    plot_gradient(\n",
    "        file_name,\n",
    "        r'$\\left[\\rm Si/Fe\\right]$',\n",
    "        gradient_SiFe,\n",
    "        absorption_lines=SiFe_absorption_lines\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a88e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "plot_gradient_Teff(star7_name_field)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0), useMathText=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plot_gradient_logg(star7_name_field)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0), useMathText=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plot_gradient_FeH(star7_name_field)\n",
    "plt.xlim(15345, 15455)\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plot_gradient_MgFe(star7_name_field)\n",
    "plt.xlim(15695, 15805)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "plot_gradient_SiFe(star7_name_field)\n",
    "plt.xlim(15920, 16130)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002fa5db",
   "metadata": {},
   "source": [
    "***Do the regions of the spectrum where the gradient is large correspond to known absorption lines?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45c0c8",
   "metadata": {},
   "source": [
    "***Additionally, plot $s_{\\lambda}^2$.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_lines = {\n",
    "    'FeH': [\n",
    "        15194.492, 15207.526, 15395.718, 15490.339,\n",
    "        15648.510, 15964.867, 16040.657, 16153.247,\n",
    "        16165.032\n",
    "    ],\n",
    "    'MgFe': [\n",
    "        15740.716, 15748.9, 15765.8,\n",
    "        15879.5, 15886.2, 15954.477\n",
    "    ],\n",
    "    'SiFe': [\n",
    "        15361.161, 15376.831, 15833.602, 15960.063,\n",
    "        16060.009, 16094.787, 16215.670, 16680.770,\n",
    "        16828.159\n",
    "    ]\n",
    "}\n",
    "\n",
    "intrinsic_scatter_sq_list = [x**2 for x in intrinsic_scatter_list]\n",
    "\n",
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# for lines in absorption_lines.values():\n",
    "#     for line in lines:\n",
    "#         plt.axvline(x=line, c='r', linestyle='--', alpha=0.5)\n",
    "        \n",
    "# plt.axvspan(15600, 15800, color='gray', alpha=0.2)\n",
    "\n",
    "# plt.plot(wavelengths_list_train[0], intrinsic_scatter_sq_list)\n",
    "# plt.ticklabel_format(style='sci', axis='both', scilimits=(0,0), useMathText=True)\n",
    "# # plt.xlim(15600, 15800)\n",
    "# plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "# plt.ylabel(r'$\\sigma_{\\rm scatter}^2$')\n",
    "# plt.title('Intrinsic Scatter')\n",
    "\n",
    "# plt.minorticks_on()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize=(10,10))\n",
    "\n",
    "for lines in absorption_lines.values():\n",
    "    for line in lines:\n",
    "        axs[0].axvline(x=line, c='r', linestyle='--', alpha=0.5)\n",
    "        axs[1].axvline(x=line, c='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "axs[0].axvspan(15600, 15800, color='gray', alpha=0.2)\n",
    "axs[0].plot(\n",
    "    wavelengths_list_train[0],\n",
    "    intrinsic_scatter_sq_list,\n",
    "    linewidth=1.5\n",
    ")\n",
    "axs[0].minorticks_on()\n",
    "axs[0].ticklabel_format(\n",
    "    style='sci',\n",
    "    axis='both',\n",
    "    scilimits=(0,0),\n",
    "    useMathText=True\n",
    ")\n",
    "axs[0].set_ylabel(r'$\\sigma_{\\rm scatter}^2$')\n",
    "axs[0].set_title('Intrinsic Scatter')\n",
    "\n",
    "axs[1].plot(\n",
    "    wavelengths_list_train[0],\n",
    "    intrinsic_scatter_sq_list,\n",
    "    linewidth=1.5\n",
    ")\n",
    "axs[1].minorticks_on()\n",
    "axs[1].set_xlim(15595, 15805)\n",
    "axs[1].ticklabel_format(\n",
    "    style='sci',\n",
    "    axis='both',\n",
    "    scilimits=(0,0),\n",
    "    useMathText=True\n",
    ")\n",
    "axs[1].set_xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "axs[1].set_ylabel(r'$\\sigma_{\\rm scatter}^2$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca4af8",
   "metadata": {},
   "source": [
    "***Do wavelengths with larger-than-average intrinsic scatter correspond to known absorption lines?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97959ff0",
   "metadata": {},
   "source": [
    "# 9. Fit for labels of spectra in testing set\n",
    "\n",
    "*To test how well the model works, use it to fit for the labels of spectra in the cross-validation set. For each spectrum in the cross-validation set, use a non-linear optimizer (Python has many options, with Trust Region Reflective (trf) in scipy.optimize.curve_fit being very robust) to find the point in label-space at which the spectrum predicted by the model best matches the observed spectrum (in a $\\chi^2$ sense, accounting for the uncertainty in the spectrum).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd77994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_fit(thetas, Teff, logg, FeH, MgFe, SiFe):\n",
    "    \n",
    "    # rescale labels based on means of training set\n",
    "    Teff = Teff - Teff_mean\n",
    "    logg = logg - logg_mean\n",
    "    FeH = FeH - FeH_mean\n",
    "    MgFe = MgFe - MgFe_mean\n",
    "    SiFe = SiFe - SiFe_mean\n",
    "    \n",
    "    # label vector\n",
    "    row = [\n",
    "        1, Teff, logg, FeH, MgFe, SiFe,\n",
    "        Teff**2, Teff*logg, Teff*FeH, Teff*MgFe, Teff*SiFe,\n",
    "        logg**2, logg*FeH, logg*MgFe, logg*SiFe,\n",
    "        FeH**2, FeH*MgFe, FeH*SiFe,\n",
    "        MgFe**2, MgFe*SiFe, \n",
    "        SiFe**2\n",
    "    ]\n",
    "    \n",
    "    flux_fit = np.matmul(thetas, row)\n",
    "    \n",
    "    return flux_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best-fit labels\n",
    "Teff_bf_list = []\n",
    "logg_bf_list = []\n",
    "FeH_bf_list = []\n",
    "MgFe_bf_list = []\n",
    "SiFe_bf_list = []\n",
    "\n",
    "Teff_bf_err_list = []\n",
    "logg_bf_err_list = []\n",
    "FeH_bf_err_list = []\n",
    "MgFe_bf_err_list = []\n",
    "SiFe_bf_err_list = []\n",
    "\n",
    "# testing set labels\n",
    "Teff_test_list = []\n",
    "logg_test_list = []\n",
    "FeH_test_list = []\n",
    "MgFe_test_list = []\n",
    "SiFe_test_list = []\n",
    "\n",
    "Teff_test_err_list = []\n",
    "logg_test_err_list = []\n",
    "FeH_test_err_list = []\n",
    "MgFe_test_err_list = []\n",
    "SiFe_test_err_list = []\n",
    "\n",
    "intrinsic_scatter = np.array(intrinsic_scatter_list)\n",
    "\n",
    "for index in range(len(label_list_test)):\n",
    "    sigma_total = np.sqrt(errors_test[index]**2 + intrinsic_scatter**2)\n",
    "    \n",
    "    opt, cov = curve_fit(\n",
    "        flux_fit,\n",
    "        np.array(thetas_matrix),\n",
    "        spectra_test[index],\n",
    "        p0=[\n",
    "            Teff_mean,\n",
    "            logg_mean,\n",
    "            FeH_mean,\n",
    "            MgFe_mean,\n",
    "            SiFe_mean\n",
    "        ],\n",
    "        sigma=sigma_total,\n",
    "        method='trf',\n",
    "        maxfev=5000\n",
    "    )\n",
    "    \n",
    "    # best fit parameters\n",
    "    Teff_bf_list.append(opt[0])\n",
    "    logg_bf_list.append(opt[1])\n",
    "    FeH_bf_list.append(opt[2])\n",
    "    MgFe_bf_list.append(opt[3])\n",
    "    SiFe_bf_list.append(opt[4])\n",
    "    \n",
    "    # fit errors\n",
    "    Teff_bf_err_list.append(cov[0,0])\n",
    "    logg_bf_err_list.append(cov[1,1])\n",
    "    FeH_bf_err_list.append(cov[2,2])\n",
    "    MgFe_bf_err_list.append(cov[3,3])\n",
    "    SiFe_bf_err_list.append(cov[4,4])\n",
    "    \n",
    "    # testing set labels\n",
    "    Teff_test_list.append(label_list_test.iloc[index]['TEFF'])\n",
    "    logg_test_list.append(label_list_test.iloc[index]['LOGG'])\n",
    "    FeH_test_list.append(label_list_test.iloc[index]['FE_H'])\n",
    "    MgFe_test_list.append(label_list_test.iloc[index]['MG_FE'])\n",
    "    SiFe_test_list.append(label_list_test.iloc[index]['SI_FE'])\n",
    "    \n",
    "    Teff_test_err_list.append(label_list_test.iloc[index]['TEFF_ERR'])\n",
    "    logg_test_err_list.append(label_list_test.iloc[index]['LOGG_ERR'])\n",
    "    FeH_test_err_list.append(label_list_test.iloc[index]['FE_H_ERR'])\n",
    "    MgFe_test_err_list.append(label_list_test.iloc[index]['MG_FE_ERR'])\n",
    "    SiFe_test_err_list.append(label_list_test.iloc[index]['SI_FE_ERR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb73b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals\n",
    "\n",
    "Teff_bf = np.array(Teff_bf_list)\n",
    "Teff_test = np.array(Teff_test_list)\n",
    "Teff_residual = Teff_test - Teff_bf\n",
    "\n",
    "logg_bf = np.array(logg_bf_list)\n",
    "logg_test = np.array(logg_test_list)\n",
    "logg_residual = logg_test - logg_bf\n",
    "\n",
    "FeH_bf = np.array(FeH_bf_list)\n",
    "FeH_test = np.array(FeH_test_list)\n",
    "FeH_residual = FeH_test - FeH_bf\n",
    "\n",
    "MgFe_bf = np.array(MgFe_bf_list)\n",
    "MgFe_test = np.array(MgFe_test_list)\n",
    "MgFe_residual = MgFe_test - MgFe_bf\n",
    "\n",
    "SiFe_bf = np.array(SiFe_bf_list)\n",
    "SiFe_test = np.array(SiFe_test_list)\n",
    "SiFe_residual = SiFe_test - SiFe_bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8420b4",
   "metadata": {},
   "source": [
    "*Now compare, for each of the five labels, the best-fit value obtained by the above procedure to the $\\texttt{ASPCAP}$-derived value in the allStar catalog for the validation set. That is, make plots of the best-fit labels vs the $\\texttt{ASPCAP}$ labels with a one-to-one line for reference, and show the residuals. Measure the ***bias*** and ***scatter*** for each label over the full cross-validation set. For a good model, these should be small; for example, a scatter of about $30 \\rm \\, K$ in $\\rm T_{eff}$ and $0.02 \\, \\rm dex$ in $\\left[\\rm Fe/H \\right]$ should be achievable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d960d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=6\n",
    "\n",
    "print(label_list_test.iloc[hh])\n",
    "print()\n",
    "print(f'Best fit Teff: {Teff_bf_list[hh]}, Teff_err: {Teff_bf_err_list[hh]}')\n",
    "print(f'Test Teff: {Teff_test_list[hh]}, Teff_err: {Teff_test_err_list[hh]}')\n",
    "print()\n",
    "print(f'Best fit logg: {logg_bf_list[hh]}, logg_err: {logg_bf_err_list[hh]}')\n",
    "print(f'Test logg: {logg_test_list[hh]}, logg_err: {logg_test_err_list[hh]}')\n",
    "print()\n",
    "print(f'Best fit FeH: {FeH_bf_list[hh]}, FeH_err: {FeH_bf_err_list[hh]}')\n",
    "print(f'Test FeH: {FeH_test_list[hh]}, FeH_err: {FeH_test_err_list[hh]}')\n",
    "print()\n",
    "print(f'Best fit MgFe: {MgFe_bf_list[hh]}, MgFe_err: {MgFe_bf_err_list[hh]}')\n",
    "print(f'Test MgFe: {MgFe_test_list[hh]}, MgFe_err: {MgFe_test_err_list[hh]}')\n",
    "print()\n",
    "print(f'Best fit SiFe: {SiFe_bf_list[hh]}, SiFe_err: {SiFe_bf_err_list[hh]}')\n",
    "print(f'Test SiFe: {SiFe_test_list[hh]}, SiFe_err: {SiFe_test_err_list[hh]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c193d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data(data_list, bf_list, test_list, bf_err_list, test_err_list):\n",
    "#     bf = np.array(bf_list)\n",
    "#     bf_err = np.array(bf_err_list)\n",
    "#     test = np.array(test_list)\n",
    "#     test_err = np.array(test_err_list)\n",
    "    \n",
    "#     residuals = test - bf\n",
    "#     mean_residuals = np.mean(residuals)\n",
    "#     std_residuals = np.std(residuals)\n",
    "    \n",
    "#     return {\n",
    "#         'bf': bf,\n",
    "#         'bf_err': bf_err,\n",
    "#         'test': test,\n",
    "#         'test_err': test_err,\n",
    "#         'residuals': residuals,\n",
    "#         'mean_residuals': mean_residuals,\n",
    "#         'std_residuals': std_residuals\n",
    "#     }\n",
    "\n",
    "# # Define data lists\n",
    "# data_lists = {\n",
    "#     'Teff': (Teff_bf_list, Teff_test_list, Teff_bf_err_list, Teff_test_err_list),\n",
    "#     'logg': (logg_bf_list, logg_test_list, logg_bf_err_list, logg_test_err_list),\n",
    "#     'FeH': (FeH_bf_list, FeH_test_list, FeH_bf_err_list, FeH_test_err_list),\n",
    "#     'MgFe': (MgFe_bf_list, MgFe_test_list, MgFe_bf_err_list, MgFe_test_err_list),\n",
    "#     'SiFe': (SiFe_bf_list, SiFe_test_list, SiFe_bf_err_list, SiFe_test_err_list)\n",
    "# }\n",
    "\n",
    "# processed_data = {}\n",
    "\n",
    "# # Process data for each variable\n",
    "# for variable, lists in data_lists.items():\n",
    "#     processed_data[variable] = process_data(*lists)\n",
    "\n",
    "# # Accessing processed data example:\n",
    "# # Teff_bf = processed_data['Teff']['bf']\n",
    "# # Teff_residuals = processed_data['Teff']['residuals']\n",
    "# # Teff_residuals_mean = processed_data['Teff']['mean_residuals']\n",
    "# # Teff_residuals_std = processed_data['Teff']['std_residuals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to arrays\n",
    "Teff_bf = np.array(Teff_bf_list)\n",
    "Teff_bf_err = np.array(Teff_bf_err_list)\n",
    "Teff_test = np.array(Teff_test_list)\n",
    "Teff_test_err = np.array(Teff_test_err_list)\n",
    "\n",
    "logg_bf = np.array(logg_bf_list)\n",
    "logg_bf_err = np.array(logg_bf_err_list)\n",
    "logg_test = np.array(logg_test_list)\n",
    "logg_test_err = np.array(logg_test_err_list)\n",
    "\n",
    "FeH_bf = np.array(FeH_bf_list)\n",
    "FeH_bf_err = np.array(FeH_bf_err_list)\n",
    "FeH_test = np.array(FeH_test_list)\n",
    "FeH_test_err = np.array(FeH_test_err_list)\n",
    "\n",
    "MgFe_bf = np.array(MgFe_bf_list)\n",
    "MgFe_bf_err = np.array(MgFe_bf_err_list)\n",
    "MgFe_test = np.array(MgFe_test_list)\n",
    "MgFe_test_err = np.array(MgFe_test_err_list)\n",
    "\n",
    "SiFe_bf = np.array(SiFe_bf_list)\n",
    "SiFe_bf_err = np.array(SiFe_bf_err_list)\n",
    "SiFe_test = np.array(SiFe_test_list)\n",
    "SiFe_test_err = np.array(SiFe_test_err_list)\n",
    "\n",
    "# residuals\n",
    "Teff_residuals = Teff_test - Teff_bf\n",
    "logg_residuals = logg_test - logg_bf\n",
    "FeH_residuals = FeH_test - FeH_bf\n",
    "MgFe_residuals = MgFe_test - MgFe_bf\n",
    "SiFe_residuals = SiFe_test - SiFe_bf\n",
    "\n",
    "# bias\n",
    "Teff_residuals_mean = np.mean(Teff_residuals)\n",
    "logg_residuals_mean = np.mean(logg_residuals)\n",
    "FeH_residuals_mean = np.mean(FeH_residuals)\n",
    "MgFe_residuals_mean = np.mean(MgFe_residuals)\n",
    "SiFe_residuals_mean = np.mean(SiFe_residuals)\n",
    "\n",
    "# scatter\n",
    "Teff_residuals_std = np.std(Teff_residuals)\n",
    "logg_residuals_std = np.std(logg_residuals)\n",
    "FeH_residuals_std = np.std(FeH_residuals)\n",
    "MgFe_residuals_std = np.std(MgFe_residuals)\n",
    "SiFe_residuals_std = np.std(SiFe_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304bc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lists = [\n",
    "    (\n",
    "        Teff_test,\n",
    "        Teff_bf,\n",
    "        Teff_test_err,\n",
    "        Teff_bf_err,\n",
    "        Teff_residuals,\n",
    "        Teff_residuals_mean,\n",
    "        Teff_residuals_std,\n",
    "        r'$\\rm T_{eff}$ [K]',\n",
    "        r'$\\rm T_{eff}$ [K]',\n",
    "        r'$\\Delta \\rm T_{eff}$ [K]'\n",
    "    ),\n",
    "    (\n",
    "        logg_test,\n",
    "        logg_bf,\n",
    "        logg_test_err,\n",
    "        logg_bf_err,\n",
    "        logg_residuals,\n",
    "        logg_residuals_mean,\n",
    "        logg_residuals_std,\n",
    "        r'$\\log \\rm g$ [dex]',\n",
    "        r'$\\log \\rm g$ [dex]',\n",
    "        r'$\\Delta \\log \\rm g$ [dex]'\n",
    "    ),\n",
    "    (\n",
    "        FeH_test,\n",
    "        FeH_bf,\n",
    "        FeH_test_err,\n",
    "        FeH_bf_err,\n",
    "        FeH_residuals,\n",
    "        FeH_residuals_mean,\n",
    "        FeH_residuals_std,\n",
    "        r'$\\left[\\rm Fe/H\\right]$ [dex]',\n",
    "        r'$\\left[\\rm Fe/H\\right]$ [dex]',\n",
    "        r'$\\Delta \\left[\\rm Fe/H\\right]$ [dex]'\n",
    "    ),\n",
    "    (\n",
    "        MgFe_test,\n",
    "        MgFe_bf,\n",
    "        MgFe_test_err,\n",
    "        MgFe_bf_err,\n",
    "        MgFe_residuals,\n",
    "        MgFe_residuals_mean,\n",
    "        MgFe_residuals_std,\n",
    "        r'$\\left[\\rm Mg/Fe\\right]$ [dex]',\n",
    "        r'$\\left[\\rm Mg/Fe\\right]$ [dex]',\n",
    "        r'$\\Delta \\left[\\rm Mg/Fe\\right]$ [dex]'\n",
    "    ),\n",
    "    (\n",
    "        SiFe_test,\n",
    "        SiFe_bf,\n",
    "        SiFe_test_err,\n",
    "        SiFe_bf_err,\n",
    "        SiFe_residuals,\n",
    "        SiFe_residuals_mean,\n",
    "        SiFe_residuals_std,\n",
    "        r'$\\left[\\rm Si/Fe\\right]$ [dex]',\n",
    "        r'$\\left[\\rm Si/Fe\\right]$ [dex]',\n",
    "        r'$\\Delta \\left[\\rm Si/Fe\\right]$ [dex]'\n",
    "    )\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(5, 2, figsize=(13, 20))\n",
    "fig.suptitle('APOGEE Labels: Model Fit vs. ASPCAP')\n",
    "fig.supxlabel('ASPCAP label inputs')\n",
    "fig.supylabel('Cannon label outputs')\n",
    "\n",
    "for i, (\n",
    "    x_data, y_data,\n",
    "    x_err, y_err,\n",
    "    residuals, residuals_mean, residuals_std,\n",
    "    xlabel, ylabel, residuals_label\n",
    ") in enumerate(data_lists):\n",
    "    row = i\n",
    "    col = 0\n",
    "    ax = axs[row, col]\n",
    "    \n",
    "    ax.errorbar(\n",
    "        x_data,\n",
    "        y_data,\n",
    "        xerr=x_err,\n",
    "        yerr=y_err,\n",
    "        fmt='none',\n",
    "        elinewidth=1.5,\n",
    "        ecolor=CB_color_cycle[1],\n",
    "        alpha=0.3,\n",
    "        zorder=0\n",
    "    )\n",
    "    ax.scatter(x_data, y_data, marker='.', s=10, c=CB_color_cycle[0])\n",
    "    ax.plot(x_data, x_data, linewidth=1.5, c=CB_color_cycle[2])\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.minorticks_on()\n",
    "    \n",
    "    bias_formatted = '{:.2g}'.format(residuals_mean)\n",
    "    scatter_formatted = '{:.2g}'.format(residuals_std)\n",
    "\n",
    "    bias_scatter_text = f'bias: {bias_formatted}\\nscatter: {scatter_formatted}'\n",
    "    ax.text(0.05, 0.95, bias_scatter_text, transform=ax.transAxes, va='top', fontsize=20)\n",
    "\n",
    "    # plot residuals\n",
    "    col = 1\n",
    "    ax = axs[row, col]\n",
    "    ax.hist(residuals, bins=50, histtype='step', color=CB_color_cycle[0], orientation='vertical')\n",
    "    ax.set_xlabel(residuals_label)\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    ax.set_ylabel('Number of Stars', rotation=270, va='bottom')\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.minorticks_on()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'results_apogee_labels_fit_vs_aspcap.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd48bdf",
   "metadata": {},
   "source": [
    "# 10.\n",
    "\n",
    "*Although the model should perform well in cross-validation in most cases, there are likely a few objects for which the best-fit labels differ substantially from those in the allStar catalog.* ***Investigate these objects, and try to find out what has gone wrong. Did the optimizer get stuck in a local minimum? Is there something wrong with the spectrum or continuum normalization? Are there flags in the catalog indicating the allStar labels might not be reliable? Can you improve your model based on these tests?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b48ee",
   "metadata": {},
   "source": [
    "# 11.\n",
    "\n",
    "***For the ~900 stars in the cross-validation set, plot a Kiel diagram (i.e. logg vs Teff). Color points by their Fe/H. Use labels obtained through fitting, not the ASPCAP labels. Identify known features. Comment on the presence (or absence) of trends with Fe/H.***\n",
    "\n",
    "*The paper by [Holtzman et al. (2015)](https://ui.adsabs.harvard.edu/abs/2015AJ....150..148H/abstract) should give a sense of what this is expected to look like.*\n",
    "\n",
    "***Download and overplot a 6 Gyr-old [MIST](https://waps.cfa.harvard.edu/MIST/interp_isos.html) isochrone of solar metallicity $\\left[\\rm Fe/H\\right] = 0$. Are the isochrones and model in good agreement? Also plot an isochrone with $\\left[\\rm Fe/H\\right] = -1$. Does the $\\left[\\rm Fe/H\\right]$-trend in the isochrones agree with what you found in your fitting?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Gyr isochrone, solar metallicity\n",
    "Zsolar_iso = Table.read(\n",
    "    'data/MIST_isochrones/MIST_iso_66071946a2439.iso',\n",
    "    format='ascii',\n",
    "    header_start = -1\n",
    ")\n",
    "\n",
    "# 6 Gyr isochrone, [Fe/H] = -1\n",
    "Zng1_iso = Table.read(\n",
    "    'data/MIST_isochrones/MIST_iso_66071d403b83f.iso',\n",
    "    format='ascii',\n",
    "    header_start = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main sequence labels\n",
    "Zsolar_logTeff = Zsolar_iso[\n",
    "    (Zsolar_iso['phase']<=2)&\n",
    "    (Zsolar_iso['phase']>=-1)\n",
    "]['log_Teff']\n",
    "Zsolar_logg = Zsolar_iso[\n",
    "    (Zsolar_iso['phase']<=2)&\n",
    "    (Zsolar_iso['phase']>=-1)\n",
    "]['log_g']\n",
    "\n",
    "Zng1_logTeff = Zng1_iso[\n",
    "    (Zng1_iso['phase']<=2)&\n",
    "    (Zng1_iso['phase']>=-1)\n",
    "]['log_Teff']\n",
    "\n",
    "Zng1_logg = Zng1_iso[\n",
    "    (Zng1_iso['phase']<=2)&\n",
    "    (Zng1_iso['phase']>=-1)\n",
    "]['log_g']\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(\n",
    "    np.log10(Teff_bf),\n",
    "    logg_bf,\n",
    "#     marker='.',\n",
    "    s=10,\n",
    "    c=FeH_bf,\n",
    "    cmap='Spectral',\n",
    "    alpha=0.75\n",
    ")\n",
    "\n",
    "# stellar_phase = [-1, 0, 2]\n",
    "# stellar_phase = {\n",
    "#     'PMS': -1,\n",
    "#     'MS': 0,\n",
    "#     'RGB': 2\n",
    "# }\n",
    "\n",
    "# for phase_label, phase in stellar_phase.items():\n",
    "#     Zsol_logTeff = Zsolar_iso[Zsolar_iso['phase']==phase]['log_Teff']\n",
    "#     Zsol_logg = Zsolar_iso[Zsolar_iso['phase']==phase]['log_g']\n",
    "    \n",
    "#     Zng1_logTeff = Zng1_iso[Zng1_iso['phase']==phase]['log_Teff']\n",
    "#     Zng1_logg = Zng1_iso[Zng1_iso['phase']==phase]['log_g']\n",
    "    \n",
    "plt.plot(\n",
    "    Zsolar_logTeff,\n",
    "    Zsolar_logg,\n",
    "    linewidth=1.5,\n",
    "    label = '[Fe/H] = 0'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    Zng1_logTeff,\n",
    "    Zng1_logg,\n",
    "    linewidth=1.5,\n",
    "    label = '[Fe/H] = -1'\n",
    ")\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='[Fe/H]')\n",
    "plt.xlabel(r'$\\log\\left(\\rm T_{eff}\\right)$ [K]')\n",
    "plt.ylabel(r'$\\log \\rm g$')\n",
    "plt.title(r'Model fit of $\\log \\rm g$ vs $\\rm T_{eff}$')\n",
    "plt.minorticks_on()\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'results_kiel_diagram.pdf',\n",
    "#     format='pdf'\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c36b8",
   "metadata": {},
   "source": [
    "# 12.\n",
    "\n",
    "*Wrap the spectral model in MCMC using $\\texttt{pymc}$. Then, use it to fit the provided [mystery spectrum](https://github.com/ucb-datalab/course_materials_2024/tree/main/labs/lab2_data). As always, state the priors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2449bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pseudo_norm_spectrum(file_path, chip_ranges, poly_order):    \n",
    "    continuum_wavelengths, pseudo_norm_spectra, pseudo_norm_errors = pseudo_continuum_normalize(\n",
    "        file_path, chip_ranges, poly_order\n",
    "    )\n",
    "\n",
    "    plt.axhline(1, linestyle='--', c='black')\n",
    "    \n",
    "#     for i, (start, end) in enumerate(chip_ranges):\n",
    "#         start_index = np.searchsorted(continuum_wavelengths, start)\n",
    "#         end_index = np.searchsorted(continuum_wavelengths, end)\n",
    "        \n",
    "#         plt.plot(\n",
    "#             continuum_wavelengths[start_index:end_index],\n",
    "#             pseudo_norm_spectra[start_index:end_index],\n",
    "#             alpha=0.5,\n",
    "#             label=f'chip {i + 1}'\n",
    "#         )\n",
    "        \n",
    "    plt.plot(\n",
    "        continuum_wavelengths,\n",
    "        pseudo_norm_spectra,\n",
    "        alpha=0.5,\n",
    "#         label=f'pseudo-normalized'\n",
    "    )\n",
    "    \n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0), useMathText=True)\n",
    "    plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "    plt.ylabel('Normalized Flux')\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_spec_file_path = 'data/mystery_spec_wiped.fits'\n",
    "\n",
    "mystery_wvl, mystery_spc, mystery_err = pseudo_continuum_normalize(\n",
    "    mystery_spec_file_path, apogee_chips, poly_order=2\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_pseudo_norm_spectrum(\n",
    "    mystery_spec_file_path,\n",
    "    apogee_chips,\n",
    "    poly_order=2\n",
    ")\n",
    "plt.title('Pseudo-normalized mystery spectrum')\n",
    "plt.minorticks_on()\n",
    "# plt.ylim(0.5, 1.5)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     figures_dir + 'result_cp1star_pseudo_norm_spectrum.pdf',\n",
    "#     format='pdf',\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f84a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(mystery_err))\n",
    "print(np.shape(intrinsic_scatter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbba6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # uniform priors\n",
    "    _Teff_prior = pm.Uniform(r'$\\rm T_{eff}$', lower=0, upper=1e5)\n",
    "    _logg_prior = pm.Uniform(r'$\\log \\rm g$', lower=0, upper=10)\n",
    "    _FeH_prior = pm.Uniform(r'$\\left\\[Fe/H\\right\\]$', lower = -2, upper=2)\n",
    "    _MgFe_prior = pm.Uniform(r'$\\left\\[Mg/Fe\\right\\]$', lower = -2, upper=2)\n",
    "    _SiFe_prior = pm.Uniform(r'$\\left\\[Si/Fe\\right\\]$', lower = -2, upper=2)\n",
    "    \n",
    "    # rescale with means of training set\n",
    "#     _Teff_rescaled = _Teff_prior - Teff_mean\n",
    "#     _logg_rescaled = _logg_prior - logg_mean\n",
    "#     _FeH_rescaled = _FeH_prior - FeH_mean\n",
    "#     _MgFe_rescaled = _MgFe_prior - MgFe_mean\n",
    "#     _SiFe_rescaled = _SiFe_prior - SiFe_mean\n",
    "    \n",
    "    # label vector\n",
    "#     _row = [\n",
    "#         1, _Teff_rescaled, _logg_rescaled, _FeH_rescaled, _MgFe_rescaled, _SiFe_rescaled,\n",
    "#         _Teff_rescaled**2, _Teff_rescaled*_logg_rescaled, _Teff_rescaled*_FeH_rescaled, _Teff_rescaled*_MgFe_rescaled, _Teff_rescaled*_SiFe_rescaled,\n",
    "#         _logg_rescaled**2, _logg_rescaled*_FeH_rescaled, _logg_rescaled*_MgFe_rescaled, _logg_rescaled*_SiFe_rescaled,\n",
    "#         _FeH_rescaled**2, _FeH_rescaled*MgFe, _FeH_rescaled*_SiFe_rescaled,\n",
    "#         _MgFe_rescaled**2, _MgFe_rescaled*_SiFe_rescaled, \n",
    "#         _SiFe_rescaled**2\n",
    "#     ]\n",
    "    \n",
    "#     _mu = 0\n",
    "    # iterate over number of free parameters\n",
    "#     for i in range(21):\n",
    "#         _mu += np.array(thetas_matrix)[:, i]*np.array(_row)[i]\n",
    "    \n",
    "    # likelihood function\n",
    "    _sigma_total = np.sqrt(mystery_err**2 + intrinsic_scatter**2)\n",
    "    \n",
    "    _mu = flux_fit(\n",
    "        np.array(thetas_matrix),\n",
    "        _Teff_prior,\n",
    "        _logg_prior,\n",
    "        _FeH_prior,\n",
    "        _MgFe_prior,\n",
    "        _SiFe_prior\n",
    "    )\n",
    "    \n",
    "    pm.Normal('obs', mu=_mu, sigma=_sigma_total, observed=mystery_spc)\n",
    "    \n",
    "    _trace = pm.sample(draws=500, tune=500, chains=2, cores=1)\n",
    "    \n",
    "    _ = pm.traceplot(\n",
    "        _trace,\n",
    "        var_names=[\n",
    "            r'$\\rm T_{eff}$',\n",
    "            r'$\\log \\rm g$',\n",
    "            r'$\\left\\[Fe/H\\right\\]$',\n",
    "            r'$\\left\\[Mg/Fe\\right\\]$',\n",
    "            r'$\\left\\[Si/Fe\\right\\]$'\n",
    "        ],\n",
    "        figsize=(10,6)\n",
    "    )\n",
    "    pm.summary(\n",
    "        _trace,\n",
    "        var_names=[\n",
    "            r'$\\rm T_{eff}$',\n",
    "            r'$\\log \\rm g$',\n",
    "            r'$\\left\\[Fe/H\\right\\]$',\n",
    "            r'$\\left\\[Mg/Fe\\right\\]$',\n",
    "            r'$\\left\\[Si/Fe\\right\\]$'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058f3e7",
   "metadata": {},
   "source": [
    "$$ \\ln p \\left(f_{n\\lambda}\\,|\\,\\theta_{\\lambda}^{T},\\,l_n,\\,s_{\\lambda}^2\\right) = -\\frac{1}{2} \\frac{\\left(f_{n\\lambda} - \\theta_{\\lambda}^{T} \\cdot l_n\\right)^2}{s_{\\lambda}^2 + \\sigma_{n\\lambda}^2} - \\frac{1}{2} \\ln \\left(s_{\\lambda}^2 + \\sigma_{n\\lambda}^2\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(mystery_spc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28af8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # uniform priors\n",
    "    _Teff_prior = pm.Uniform(r'$\\rm T_{eff}$', lower=0, upper=1e5)\n",
    "    _logg_prior = pm.Uniform(r'$\\log \\rm g$', lower=0, upper=10)\n",
    "    _FeH_prior = pm.Uniform(r'$\\left\\[Fe/H\\right\\]$', lower = -2, upper=2)\n",
    "    _MgFe_prior = pm.Uniform(r'$\\left\\[Mg/Fe\\right\\]$', lower = -2, upper=2)\n",
    "    _SiFe_prior = pm.Uniform(r'$\\left\\[Si/Fe\\right\\]$', lower = -2, upper=2)\n",
    "    \n",
    "    # rescale with means of training set\n",
    "    _Teff_rescaled = _Teff_prior - Teff_mean\n",
    "    _logg_rescaled = _logg_prior - logg_mean\n",
    "    _FeH_rescaled = _FeH_prior - FeH_mean\n",
    "    _MgFe_rescaled = _MgFe_prior - MgFe_mean\n",
    "    _SiFe_rescaled = _SiFe_prior - SiFe_mean\n",
    "    \n",
    "    # label vector\n",
    "    _row = [\n",
    "        1, _Teff_rescaled, _logg_rescaled, _FeH_rescaled, _MgFe_rescaled, _SiFe_rescaled,\n",
    "        _Teff_rescaled**2, _Teff_rescaled*_logg_rescaled, _Teff_rescaled*_FeH_rescaled, _Teff_rescaled*_MgFe_rescaled, _Teff_rescaled*_SiFe_rescaled,\n",
    "        _logg_rescaled**2, _logg_rescaled*_FeH_rescaled, _logg_rescaled*_MgFe_rescaled, _logg_rescaled*_SiFe_rescaled,\n",
    "        _FeH_rescaled**2, _FeH_rescaled*MgFe, _FeH_rescaled*_SiFe_rescaled,\n",
    "        _MgFe_rescaled**2, _MgFe_rescaled*_SiFe_rescaled, \n",
    "        _SiFe_rescaled**2\n",
    "    ]\n",
    "    \n",
    "#     _mu = 0\n",
    "    # iterate over number of free parameters\n",
    "#     for i in range(21):\n",
    "#         _mu += np.array(thetas_matrix)[:, i]*np.array(_row)[i]\n",
    "    \n",
    "    # total uncertainty\n",
    "    _sigma_total = np.sqrt(mystery_err**2 + intrinsic_scatter**2)\n",
    "    \n",
    "    # log likelihood terms\n",
    "    exp_term = 0\n",
    "    for i in range(21):\n",
    "        exp_term += (mystery_spc - np.array(thetas_matrix)[i])\n",
    "    \n",
    "    _mu = flux_fit(\n",
    "        np.array(thetas_matrix),\n",
    "        _Teff_rescaled,\n",
    "        _logg_rescaled,\n",
    "        _FeH_rescaled,\n",
    "        _MgFe_rescaled,\n",
    "        _SiFe_rescaled\n",
    "    )\n",
    "    \n",
    "    pm.Normal('obs', mu=_mu, sigma=_sigma_total, observed=mystery_spc)\n",
    "    \n",
    "    _trace = pm.sample(draws=500, tune=500, chains=2, cores=1)\n",
    "    \n",
    "    _ = pm.traceplot(\n",
    "        _trace,\n",
    "        var_names=[\n",
    "            r'$\\rm T_{eff}$',\n",
    "            r'$\\log \\rm g$',\n",
    "            r'$\\left\\[Fe/H\\right\\]$',\n",
    "            r'$\\left\\[Mg/Fe\\right\\]$',\n",
    "            r'$\\left\\[Si/Fe\\right\\]$'\n",
    "        ],\n",
    "        figsize=(10,6)\n",
    "    )\n",
    "    pm.summary(\n",
    "        _trace,\n",
    "        var_names=[\n",
    "            r'$\\rm T_{eff}$',\n",
    "            r'$\\log \\rm g$',\n",
    "            r'$\\left\\[Fe/H\\right\\]$',\n",
    "            r'$\\left\\[Mg/Fe\\right\\]$',\n",
    "            r'$\\left\\[Si/Fe\\right\\]$'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f08e1b",
   "metadata": {},
   "source": [
    "# 13.\n",
    "\n",
    "***Use your model to make a plot using color and offset spectra that shows how the spectrum changes with metallicity at fixed Teff and logg. For clarity, show only the region of the spectrum from 16000 to 16200 Angstroms. Vary \\[Fe/H\\] from -1 to 0.5 and fix the atmospheric parameters to reasonable values.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d50813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_spectrum_13(Teff, logg, FeH, MgFe, SiFe):\n",
    "    \n",
    "    # label vector\n",
    "    row = [\n",
    "        1, Teff, logg, FeH, MgFe, SiFe,\n",
    "        Teff**2, Teff*logg, Teff*FeH, Teff*MgFe, Teff*SiFe,\n",
    "        logg**2, logg*FeH, logg*MgFe, logg*SiFe,\n",
    "        FeH**2, FeH*MgFe, FeH*SiFe,\n",
    "        MgFe**2, MgFe*SiFe, \n",
    "        SiFe**2\n",
    "    ]\n",
    "    \n",
    "    spectrum_model_list = []\n",
    "\n",
    "    for wavelength_bin in range(len(thetas_matrix)):\n",
    "        flux_model_value = np.matmul(row, thetas_matrix[wavelength_bin])\n",
    "        spectrum_model_list.append(flux_model_value)\n",
    "    \n",
    "    spectrum_model = np.array(spectrum_model_list)\n",
    "    \n",
    "    return spectrum_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeH_var = np.linspace(-1, 0.5, 6)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "offset = 0\n",
    "\n",
    "for FeH_value in FeH_var:\n",
    "    spectrum_model = model_spectrum_13(\n",
    "        Teff_mean,\n",
    "        logg_mean,\n",
    "        FeH_value,\n",
    "        MgFe_mean,\n",
    "        SiFe_mean\n",
    "    )\n",
    "    plt.plot(\n",
    "        wavelengths_list_train[0],\n",
    "        spectrum_model + offset,\n",
    "        label=f'[Fe/H] = {np.round(FeH_value, 1)}'\n",
    "    )\n",
    "    \n",
    "    offset += 7\n",
    "\n",
    "plt.xlim(15995, 16205)\n",
    "plt.ylim(-15,70)\n",
    "plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "plt.ylabel('Normalized Offset Flux')\n",
    "plt.title('Offset Spectra Varying Metallicity')\n",
    "plt.minorticks_on()\n",
    "plt.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2473f",
   "metadata": {},
   "source": [
    "# 14.\n",
    "\n",
    "***Make a plot using color and offset spectra to show how the same region of the spectrum changes as a star ascends the red giant branch. Fix $\\left[\\rm Fe/H\\right] = 0$, and vary $\\log \\rm g$ from $3.5$ to $0.5$, simultaneously varying $\\rm T_{eff}$ such that the star moves along an isochrone.***\n",
    "\n",
    "***Comment on the similarities and differences of how the spectrum changes when the composition changes vs. when the star moves up the RGB at fixed composition. How can one tell the differences between a cool, low-$\\log \\rm g$ star and a warmer, higher-$\\log \\rm g$ star that is more metal-rich?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logg_var = np.linspace(3.5, 0.5, 6)\n",
    "# from kiel diagram\n",
    "teff_var = np.linspace(10**(3.7), 10**(3.5), 6)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "offset = 0\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(len(logg_var)):\n",
    "    spectrum_model = model_spectrum_13(\n",
    "        teff_var[i],\n",
    "        logg_var[i],\n",
    "        0, 0, 0\n",
    "    )\n",
    "    plt.plot(\n",
    "        wavelengths_list_train[0],\n",
    "        spectrum_model + offset,\n",
    "        label=fr'$\\log \\rm g$ = {np.round(logg_var[i], 1)}'\n",
    "    )\n",
    "    \n",
    "    offset += 7\n",
    "\n",
    "plt.xlim(15995, 16205)\n",
    "plt.ylim(-15,70)\n",
    "plt.xlabel(r'$\\lambda$ $\\left[\\AA\\right]$')\n",
    "plt.ylabel('Normalized Offset Flux')\n",
    "plt.title('Offset Spectra Varying Surface Gravity \\n and Effective Temperature')\n",
    "plt.minorticks_on()\n",
    "plt.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d3c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
